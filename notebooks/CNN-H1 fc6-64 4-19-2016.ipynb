{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN-H1 4-19-2016</h1>\n",
    "\n",
    "<strong>Abstract</strong>\n",
    "Implementing the CNN-H1 using NN2 described in the paper: http://arxiv.org/pdf/1509.00244v1.pdf. \n",
    "\n",
    "<strong>Improvements</strong>\n",
    "<ul>\n",
    "<li>Narrowed the width of faces to focus on the face, cut out background</li>\n",
    "<li>Validation split of 15%</li>\n",
    "<li>fc6 layer has a length of 64</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GRID K520 (CNMeM is enabled with initial size: 98.0% of memory, CuDNN 3007)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/lfw_cropped'\n",
    "\n",
    "img_rows_load, img_cols_load = 160, 160\n",
    "img_rows, img_cols = 160, 120\n",
    "num_people = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading Files</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_path_dict():\n",
    "    face_to_file_paths_dict = {}\n",
    "    \n",
    "    for root, dirnames, filenames in os.walk(data_path):\n",
    "        for dirname in dirnames:\n",
    "            if dirname not in face_to_file_paths_dict:\n",
    "                face_to_file_paths_dict[dirname] = []\n",
    "            directory_path = os.path.join(data_path, dirname)\n",
    "            for filename in os.listdir(directory_path):\n",
    "                if filename.endswith(\".jpg\"):\n",
    "                    face_to_file_paths_dict[dirname].append(os.path.join(directory_path, filename))\n",
    "                            \n",
    "    return face_to_file_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_paths_descending_list(face_to_file_paths_dict):\n",
    "    return sorted(face_to_file_paths_dict.items(), key=lambda x: len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_dict = get_face_to_file_path_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_list = get_face_to_file_paths_descending_list(face_to_file_paths_dict)[:num_people]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Pre-Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_read(f):\n",
    "    return resize(rgb2grey(io.imread(f)), (img_rows_load, img_cols_load))\n",
    "\n",
    "def reflection(image):\n",
    "    return np.array([list(reversed(row)) for row in image])\n",
    "\n",
    "def partition(image, top_left, rows, cols):\n",
    "    return np.array([row[top_left[1]:top_left[1] + cols] for row in image[top_left[0]:top_left[0] + rows]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_by_class = [[image_read(f) for f in x[1]] for x in face_to_file_paths_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_by_class)):\n",
    "    images_by_class[i] += [reflection(im) for im in images_by_class[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_by_class)):\n",
    "    images_by_class[i] = [partition(im, (0, 20), img_rows, img_cols) for im in images_by_class[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([image for images in images_by_class for image in images])\n",
    "y_train = np.array([images[0] for images in enumerate(images_by_class) for image in images[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipped = np.array(zip(X_train, y_train))\n",
    "np.random.shuffle(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([x[0] for x in zipped])\n",
    "y_train = np.array([x[1] for x in zipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "Y_train = np_utils.to_categorical(y_train, len(images_by_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training and Validation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN2(input_shape, nb_classes, nb_fc6):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 4\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 5\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(AveragePooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(nb_fc6))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (1, img_rows, img_cols)\n",
    "nb_fc6 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11352 samples, validate on 2004 samples\n",
      "Epoch 1/10\n",
      "11352/11352 [==============================] - 353s - loss: 6.0286 - acc: 0.0697 - val_loss: 5.8939 - val_acc: 0.0853\n",
      "Epoch 2/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.8030 - acc: 0.0773 - val_loss: 5.8424 - val_acc: 0.0853\n",
      "Epoch 3/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.7607 - acc: 0.0778 - val_loss: 5.8124 - val_acc: 0.0853\n",
      "Epoch 4/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.7428 - acc: 0.0780 - val_loss: 5.8136 - val_acc: 0.0853\n",
      "Epoch 5/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.7381 - acc: 0.0781 - val_loss: 5.8155 - val_acc: 0.0853\n",
      "Epoch 6/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.7255 - acc: 0.0780 - val_loss: 5.7886 - val_acc: 0.0853\n",
      "Epoch 7/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.7139 - acc: 0.0781 - val_loss: 5.8030 - val_acc: 0.0853\n",
      "Epoch 8/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.6903 - acc: 0.0780 - val_loss: 5.7385 - val_acc: 0.0853\n",
      "Epoch 9/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.6515 - acc: 0.0788 - val_loss: 5.6653 - val_acc: 0.0848\n",
      "Epoch 10/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.5890 - acc: 0.0847 - val_loss: 5.6758 - val_acc: 0.0898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff806228110>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN2(input_shape, num_people, nb_fc6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, \n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/CNN-H1-fc6-64-10e.json', 'w').write(json_string)\n",
    "model.save_weights('models/CNN-H1-fc6-64-10e.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11352 samples, validate on 2004 samples\n",
      "Epoch 1/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.4542 - acc: 0.0914 - val_loss: 5.5558 - val_acc: 0.0918\n",
      "Epoch 2/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.4195 - acc: 0.0964 - val_loss: 5.5158 - val_acc: 0.0998\n",
      "Epoch 3/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.3883 - acc: 0.1002 - val_loss: 5.4803 - val_acc: 0.1038\n",
      "Epoch 4/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.3557 - acc: 0.1083 - val_loss: 5.4363 - val_acc: 0.1058\n",
      "Epoch 5/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.3150 - acc: 0.1147 - val_loss: 5.4124 - val_acc: 0.1163\n",
      "Epoch 6/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.2655 - acc: 0.1205 - val_loss: 5.3638 - val_acc: 0.1243\n",
      "Epoch 7/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.2167 - acc: 0.1329 - val_loss: 5.3047 - val_acc: 0.1342\n",
      "Epoch 8/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.1680 - acc: 0.1394 - val_loss: 5.2974 - val_acc: 0.1347\n",
      "Epoch 9/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.1035 - acc: 0.1524 - val_loss: 5.2387 - val_acc: 0.1397\n",
      "Epoch 10/100\n",
      "11352/11352 [==============================] - 353s - loss: 5.0317 - acc: 0.1593 - val_loss: 5.1161 - val_acc: 0.1592\n",
      "Epoch 11/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.9455 - acc: 0.1722 - val_loss: 5.0309 - val_acc: 0.1687\n",
      "Epoch 12/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.8567 - acc: 0.1839 - val_loss: 4.9815 - val_acc: 0.1677\n",
      "Epoch 13/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.7563 - acc: 0.1944 - val_loss: 4.9085 - val_acc: 0.1826\n",
      "Epoch 14/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.6752 - acc: 0.2101 - val_loss: 4.8387 - val_acc: 0.1911\n",
      "Epoch 15/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.5748 - acc: 0.2209 - val_loss: 4.7347 - val_acc: 0.2066\n",
      "Epoch 16/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.4651 - acc: 0.2351 - val_loss: 4.6472 - val_acc: 0.2116\n",
      "Epoch 17/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.3539 - acc: 0.2511 - val_loss: 4.6848 - val_acc: 0.2231\n",
      "Epoch 18/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.2471 - acc: 0.2627 - val_loss: 4.5642 - val_acc: 0.2280\n",
      "Epoch 19/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.1407 - acc: 0.2713 - val_loss: 4.4377 - val_acc: 0.2525\n",
      "Epoch 20/100\n",
      "11352/11352 [==============================] - 353s - loss: 4.0228 - acc: 0.2867 - val_loss: 4.3103 - val_acc: 0.2670\n",
      "Epoch 21/100\n",
      "11352/11352 [==============================] - 353s - loss: 3.8920 - acc: 0.3024 - val_loss: 4.2554 - val_acc: 0.2710\n",
      "Epoch 22/100\n",
      "11352/11352 [==============================] - 353s - loss: 3.7682 - acc: 0.3184 - val_loss: 4.3825 - val_acc: 0.2690\n",
      "Epoch 23/100\n",
      "11352/11352 [==============================] - 353s - loss: 3.6461 - acc: 0.3316 - val_loss: 4.0732 - val_acc: 0.2904\n",
      "Epoch 24/100\n",
      "11352/11352 [==============================] - 353s - loss: 3.5109 - acc: 0.3498 - val_loss: 3.9897 - val_acc: 0.2949\n",
      "Epoch 25/100\n",
      "11352/11352 [==============================] - 353s - loss: 3.3872 - acc: 0.3591 - val_loss: 3.8788 - val_acc: 0.3184\n",
      "Epoch 26/100\n",
      "11352/11352 [==============================] - 353s - loss: 3.2643 - acc: 0.3765 - val_loss: 3.7192 - val_acc: 0.3343\n",
      "Epoch 27/100\n",
      "11352/11352 [==============================] - 353s - loss: 3.1104 - acc: 0.3969 - val_loss: 3.7263 - val_acc: 0.3273\n",
      "Epoch 28/100\n",
      "11352/11352 [==============================] - 353s - loss: 2.9718 - acc: 0.4158 - val_loss: 3.8394 - val_acc: 0.3169\n",
      "Epoch 29/100\n",
      "11352/11352 [==============================] - 353s - loss: 2.8210 - acc: 0.4335 - val_loss: 3.7502 - val_acc: 0.3348\n",
      "Epoch 30/100\n",
      "11352/11352 [==============================] - 353s - loss: 2.7015 - acc: 0.4532 - val_loss: 3.5071 - val_acc: 0.3443\n",
      "Epoch 31/100\n",
      "11352/11352 [==============================] - 353s - loss: 2.5435 - acc: 0.4769 - val_loss: 3.4802 - val_acc: 0.3533\n",
      "Epoch 32/100\n",
      "11352/11352 [==============================] - 353s - loss: 2.3953 - acc: 0.4957 - val_loss: 3.2426 - val_acc: 0.3902\n",
      "Epoch 33/100\n",
      "11352/11352 [==============================] - 353s - loss: 2.2621 - acc: 0.5145 - val_loss: 3.1987 - val_acc: 0.3947\n",
      "Epoch 34/100\n",
      "11352/11352 [==============================] - 353s - loss: 2.1293 - acc: 0.5345 - val_loss: 3.2388 - val_acc: 0.3897\n",
      "Epoch 35/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.9747 - acc: 0.5582 - val_loss: 3.1423 - val_acc: 0.4077\n",
      "Epoch 36/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.8327 - acc: 0.5854 - val_loss: 3.0482 - val_acc: 0.4147\n",
      "Epoch 37/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.7062 - acc: 0.6029 - val_loss: 3.0626 - val_acc: 0.4207\n",
      "Epoch 38/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.5732 - acc: 0.6270 - val_loss: 2.9365 - val_acc: 0.4476\n",
      "Epoch 39/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.4393 - acc: 0.6541 - val_loss: 3.1353 - val_acc: 0.4256\n",
      "Epoch 40/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.3334 - acc: 0.6703 - val_loss: 2.8689 - val_acc: 0.4506\n",
      "Epoch 41/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.2028 - acc: 0.7028 - val_loss: 2.8326 - val_acc: 0.4591\n",
      "Epoch 42/100\n",
      "11352/11352 [==============================] - 353s - loss: 1.0860 - acc: 0.7265 - val_loss: 2.9214 - val_acc: 0.4596\n",
      "Epoch 43/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.9990 - acc: 0.7363 - val_loss: 2.8455 - val_acc: 0.4671\n",
      "Epoch 44/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.8904 - acc: 0.7652 - val_loss: 2.8314 - val_acc: 0.4726\n",
      "Epoch 45/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.7865 - acc: 0.7857 - val_loss: 2.7750 - val_acc: 0.4825\n",
      "Epoch 46/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.7064 - acc: 0.8051 - val_loss: 2.9745 - val_acc: 0.4646\n",
      "Epoch 47/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.6041 - acc: 0.8332 - val_loss: 2.7039 - val_acc: 0.4955\n",
      "Epoch 48/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.5685 - acc: 0.8404 - val_loss: 2.7284 - val_acc: 0.5035\n",
      "Epoch 49/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.5093 - acc: 0.8542 - val_loss: 2.8782 - val_acc: 0.4860\n",
      "Epoch 50/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.4337 - acc: 0.8717 - val_loss: 3.1872 - val_acc: 0.4860\n",
      "Epoch 51/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.4077 - acc: 0.8785 - val_loss: 2.8647 - val_acc: 0.4950\n",
      "Epoch 52/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.3687 - acc: 0.8880 - val_loss: 2.8019 - val_acc: 0.5150\n",
      "Epoch 53/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.2938 - acc: 0.9101 - val_loss: 2.8364 - val_acc: 0.5055\n",
      "Epoch 54/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.2739 - acc: 0.9141 - val_loss: 2.8475 - val_acc: 0.5205\n",
      "Epoch 55/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.2579 - acc: 0.9205 - val_loss: 2.9526 - val_acc: 0.5235\n",
      "Epoch 56/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.2298 - acc: 0.9298 - val_loss: 3.0235 - val_acc: 0.5055\n",
      "Epoch 57/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.2031 - acc: 0.9391 - val_loss: 2.9143 - val_acc: 0.5230\n",
      "Epoch 58/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1829 - acc: 0.9413 - val_loss: 2.8415 - val_acc: 0.5369\n",
      "Epoch 59/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1803 - acc: 0.9434 - val_loss: 2.9089 - val_acc: 0.5250\n",
      "Epoch 60/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1619 - acc: 0.9493 - val_loss: 2.9280 - val_acc: 0.5374\n",
      "Epoch 61/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1496 - acc: 0.9527 - val_loss: 3.2982 - val_acc: 0.5215\n",
      "Epoch 62/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1404 - acc: 0.9559 - val_loss: 3.0041 - val_acc: 0.5419\n",
      "Epoch 63/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1267 - acc: 0.9618 - val_loss: 2.9388 - val_acc: 0.5319\n",
      "Epoch 64/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1114 - acc: 0.9641 - val_loss: 2.9570 - val_acc: 0.5549\n",
      "Epoch 65/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.1175 - acc: 0.9631 - val_loss: 3.0845 - val_acc: 0.5374\n",
      "Epoch 66/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0983 - acc: 0.9680 - val_loss: 2.9401 - val_acc: 0.5544\n",
      "Epoch 67/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0941 - acc: 0.9687 - val_loss: 3.1301 - val_acc: 0.5399\n",
      "Epoch 68/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0796 - acc: 0.9752 - val_loss: 3.1834 - val_acc: 0.5459\n",
      "Epoch 69/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0977 - acc: 0.9711 - val_loss: 3.0547 - val_acc: 0.5584\n",
      "Epoch 70/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0870 - acc: 0.9709 - val_loss: 2.9817 - val_acc: 0.5564\n",
      "Epoch 71/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0722 - acc: 0.9766 - val_loss: 2.8152 - val_acc: 0.5644\n",
      "Epoch 72/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0725 - acc: 0.9784 - val_loss: 3.0741 - val_acc: 0.5534\n",
      "Epoch 73/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0672 - acc: 0.9780 - val_loss: 2.9423 - val_acc: 0.5664\n",
      "Epoch 74/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0671 - acc: 0.9775 - val_loss: 3.0196 - val_acc: 0.5763\n",
      "Epoch 75/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0623 - acc: 0.9793 - val_loss: 3.1029 - val_acc: 0.5584\n",
      "Epoch 76/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0576 - acc: 0.9820 - val_loss: 2.9568 - val_acc: 0.5679\n",
      "Epoch 77/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0560 - acc: 0.9817 - val_loss: 2.8893 - val_acc: 0.5664\n",
      "Epoch 78/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0486 - acc: 0.9842 - val_loss: 3.1199 - val_acc: 0.5529\n",
      "Epoch 79/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0618 - acc: 0.9797 - val_loss: 3.1924 - val_acc: 0.5539\n",
      "Epoch 80/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0545 - acc: 0.9835 - val_loss: 3.0427 - val_acc: 0.5753\n",
      "Epoch 81/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0454 - acc: 0.9859 - val_loss: 2.9568 - val_acc: 0.5704\n",
      "Epoch 82/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0464 - acc: 0.9854 - val_loss: 2.9979 - val_acc: 0.5793\n",
      "Epoch 83/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0461 - acc: 0.9854 - val_loss: 3.0743 - val_acc: 0.5624\n",
      "Epoch 84/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0526 - acc: 0.9845 - val_loss: 2.9458 - val_acc: 0.5709\n",
      "Epoch 85/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0442 - acc: 0.9859 - val_loss: 2.9118 - val_acc: 0.5838\n",
      "Epoch 86/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0501 - acc: 0.9840 - val_loss: 2.8984 - val_acc: 0.5778\n",
      "Epoch 87/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0423 - acc: 0.9862 - val_loss: 2.9781 - val_acc: 0.5783\n",
      "Epoch 88/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0481 - acc: 0.9849 - val_loss: 2.9654 - val_acc: 0.5773\n",
      "Epoch 89/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0309 - acc: 0.9909 - val_loss: 2.9569 - val_acc: 0.5828\n",
      "Epoch 90/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0501 - acc: 0.9828 - val_loss: 3.0434 - val_acc: 0.5739\n",
      "Epoch 91/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0344 - acc: 0.9896 - val_loss: 3.0088 - val_acc: 0.5853\n",
      "Epoch 92/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0331 - acc: 0.9905 - val_loss: 2.9520 - val_acc: 0.5833\n",
      "Epoch 93/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0340 - acc: 0.9890 - val_loss: 2.9602 - val_acc: 0.5883\n",
      "Epoch 94/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0311 - acc: 0.9910 - val_loss: 2.9429 - val_acc: 0.5958\n",
      "Epoch 95/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0324 - acc: 0.9891 - val_loss: 3.0509 - val_acc: 0.5898\n",
      "Epoch 96/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0257 - acc: 0.9923 - val_loss: 2.9303 - val_acc: 0.5923\n",
      "Epoch 97/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0310 - acc: 0.9911 - val_loss: 3.0951 - val_acc: 0.5863\n",
      "Epoch 98/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0205 - acc: 0.9939 - val_loss: 2.9427 - val_acc: 0.5968\n",
      "Epoch 99/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0265 - acc: 0.9908 - val_loss: 2.9571 - val_acc: 0.5913\n",
      "Epoch 100/100\n",
      "11352/11352 [==============================] - 353s - loss: 0.0274 - acc: 0.9912 - val_loss: 3.0425 - val_acc: 0.5883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6aba45810>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001))\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=100,\n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/CNN-H1-fc6-64-110.json', 'w').write(json_string)\n",
    "model.save_weights('models/CNN-H1-fc6-64-110e.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
