{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN-H1 4-19-2016</h1>\n",
    "\n",
    "<strong>Abstract</strong>\n",
    "Implementing the CNN-H1 using NN2 described in the paper: http://arxiv.org/pdf/1509.00244v1.pdf. \n",
    "\n",
    "<strong>Improvements</strong>\n",
    "<ul>\n",
    "<li>Narrowed the width of faces to focus on the face, cut out background</li>\n",
    "<li>Validation split of 15%</li>\n",
    "<li>fc6 layer has a length of 512</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 2: GRID K520 (CNMeM is enabled with initial size: 98.0% of memory, CuDNN 3007)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/lfw_cropped'\n",
    "\n",
    "img_rows_load, img_cols_load = 160, 160\n",
    "img_rows, img_cols = 160, 120\n",
    "num_people = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading Files</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_path_dict():\n",
    "    face_to_file_paths_dict = {}\n",
    "    \n",
    "    for root, dirnames, filenames in os.walk(data_path):\n",
    "        for dirname in dirnames:\n",
    "            if dirname not in face_to_file_paths_dict:\n",
    "                face_to_file_paths_dict[dirname] = []\n",
    "            directory_path = os.path.join(data_path, dirname)\n",
    "            for filename in os.listdir(directory_path):\n",
    "                if filename.endswith(\".jpg\"):\n",
    "                    face_to_file_paths_dict[dirname].append(os.path.join(directory_path, filename))\n",
    "                            \n",
    "    return face_to_file_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_paths_descending_list(face_to_file_paths_dict):\n",
    "    return sorted(face_to_file_paths_dict.items(), key=lambda x: len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_dict = get_face_to_file_path_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_list = get_face_to_file_paths_descending_list(face_to_file_paths_dict)[:num_people]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Pre-Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_read(f):\n",
    "    return resize(rgb2grey(io.imread(f)), (img_rows_load, img_cols_load))\n",
    "\n",
    "def reflection(image):\n",
    "    return np.array([list(reversed(row)) for row in image])\n",
    "\n",
    "def partition(image, top_left, rows, cols):\n",
    "    return np.array([row[top_left[1]:top_left[1] + cols] for row in image[top_left[0]:top_left[0] + rows]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_by_class = [[image_read(f) for f in x[1]] for x in face_to_file_paths_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_by_class)):\n",
    "    images_by_class[i] += [reflection(im) for im in images_by_class[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_by_class)):\n",
    "    images_by_class[i] = [partition(im, (0, 20), img_rows, img_cols) for im in images_by_class[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([image for images in images_by_class for image in images])\n",
    "y_train = np.array([images[0] for images in enumerate(images_by_class) for image in images[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipped = np.array(zip(X_train, y_train))\n",
    "np.random.shuffle(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([x[0] for x in zipped])\n",
    "y_train = np.array([x[1] for x in zipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "Y_train = np_utils.to_categorical(y_train, len(images_by_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training and Validation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN2(input_shape, nb_classes, nb_fc6):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 4\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 5\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(AveragePooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(nb_fc6))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (1, img_rows, img_cols)\n",
    "nb_fc6 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11352 samples, validate on 2004 samples\n",
      "Epoch 1/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.9699 - acc: 0.0662 - val_loss: 5.8469 - val_acc: 0.0349\n",
      "Epoch 2/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.7831 - acc: 0.0768 - val_loss: 5.8227 - val_acc: 0.0853\n",
      "Epoch 3/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.7551 - acc: 0.0778 - val_loss: 5.8151 - val_acc: 0.0853\n",
      "Epoch 4/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.2171 - acc: 0.1189 - val_loss: 5.2110 - val_acc: 0.1272\n",
      "Epoch 10/10\n",
      "11352/11352 [==============================] - 354s - loss: 4.8056 - acc: 0.1653 - val_loss: 4.7766 - val_acc: 0.1766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96fca96190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN2(input_shape, num_people, nb_fc6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, \n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/CNN-H1-fc6-512-10e.json', 'w').write(json_string)\n",
    "model.save_weights('models/CNN-H1-fc6-512-10e.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11352 samples, validate on 2004 samples\n",
      "Epoch 1/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.0627 - acc: 0.2541 - val_loss: 4.3662 - val_acc: 0.2510\n",
      "Epoch 2/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.8572 - acc: 0.2764 - val_loss: 4.2221 - val_acc: 0.2645\n",
      "Epoch 3/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.6979 - acc: 0.2997 - val_loss: 4.1402 - val_acc: 0.2779\n",
      "Epoch 4/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.5541 - acc: 0.3193 - val_loss: 4.0122 - val_acc: 0.2904\n",
      "Epoch 5/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.4076 - acc: 0.3305 - val_loss: 3.9807 - val_acc: 0.2944\n",
      "Epoch 6/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.2630 - acc: 0.3523 - val_loss: 3.8150 - val_acc: 0.3154\n",
      "Epoch 7/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.1074 - acc: 0.3717 - val_loss: 3.6948 - val_acc: 0.3363\n",
      "Epoch 8/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.9656 - acc: 0.3832 - val_loss: 3.6684 - val_acc: 0.3323\n",
      "Epoch 9/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.8115 - acc: 0.4101 - val_loss: 3.6044 - val_acc: 0.3323\n",
      "Epoch 10/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.6476 - acc: 0.4344 - val_loss: 3.4200 - val_acc: 0.3648\n",
      "Epoch 11/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.5063 - acc: 0.4534 - val_loss: 3.3561 - val_acc: 0.3643\n",
      "Epoch 12/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.3328 - acc: 0.4841 - val_loss: 3.3012 - val_acc: 0.3782\n",
      "Epoch 13/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.1872 - acc: 0.5085 - val_loss: 3.1998 - val_acc: 0.3982\n",
      "Epoch 14/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.0370 - acc: 0.5316 - val_loss: 3.1027 - val_acc: 0.4032\n",
      "Epoch 15/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.8755 - acc: 0.5592 - val_loss: 3.1209 - val_acc: 0.4107\n",
      "Epoch 16/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.7098 - acc: 0.5891 - val_loss: 3.0387 - val_acc: 0.4291\n",
      "Epoch 17/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.5811 - acc: 0.6135 - val_loss: 2.9161 - val_acc: 0.4336\n",
      "Epoch 18/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.4227 - acc: 0.6439 - val_loss: 2.8910 - val_acc: 0.4476\n",
      "Epoch 19/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.3058 - acc: 0.6655 - val_loss: 2.8741 - val_acc: 0.4506\n",
      "Epoch 20/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.1684 - acc: 0.7001 - val_loss: 2.8235 - val_acc: 0.4646\n",
      "Epoch 21/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.0398 - acc: 0.7273 - val_loss: 2.7612 - val_acc: 0.4760\n",
      "Epoch 22/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.9437 - acc: 0.7469 - val_loss: 2.7534 - val_acc: 0.4815\n",
      "Epoch 23/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.8342 - acc: 0.7723 - val_loss: 2.7171 - val_acc: 0.4880\n",
      "Epoch 24/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.7329 - acc: 0.7930 - val_loss: 2.7436 - val_acc: 0.4875\n",
      "Epoch 25/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.6421 - acc: 0.8206 - val_loss: 2.8163 - val_acc: 0.4955\n",
      "Epoch 26/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.5939 - acc: 0.8259 - val_loss: 2.7992 - val_acc: 0.4985\n",
      "Epoch 27/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.5170 - acc: 0.8523 - val_loss: 2.7990 - val_acc: 0.5040\n",
      "Epoch 28/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.4360 - acc: 0.8667 - val_loss: 2.8503 - val_acc: 0.5185\n",
      "Epoch 29/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.4061 - acc: 0.8751 - val_loss: 2.6869 - val_acc: 0.5185\n",
      "Epoch 30/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.3568 - acc: 0.8927 - val_loss: 2.7060 - val_acc: 0.5289\n",
      "Epoch 31/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.3145 - acc: 0.9030 - val_loss: 2.7744 - val_acc: 0.5399\n",
      "Epoch 32/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2861 - acc: 0.9138 - val_loss: 2.9400 - val_acc: 0.5319\n",
      "Epoch 33/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2512 - acc: 0.9216 - val_loss: 2.8955 - val_acc: 0.5304\n",
      "Epoch 34/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2402 - acc: 0.9256 - val_loss: 2.8368 - val_acc: 0.5384\n",
      "Epoch 35/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2131 - acc: 0.9316 - val_loss: 2.8633 - val_acc: 0.5359\n",
      "Epoch 36/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1930 - acc: 0.9397 - val_loss: 2.9533 - val_acc: 0.5349\n",
      "Epoch 37/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1840 - acc: 0.9423 - val_loss: 2.9947 - val_acc: 0.5364\n",
      "Epoch 38/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1631 - acc: 0.9473 - val_loss: 2.8196 - val_acc: 0.5589\n",
      "Epoch 39/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1476 - acc: 0.9535 - val_loss: 2.8995 - val_acc: 0.5474\n",
      "Epoch 40/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1430 - acc: 0.9550 - val_loss: 3.0045 - val_acc: 0.5519\n",
      "Epoch 41/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1326 - acc: 0.9584 - val_loss: 2.8771 - val_acc: 0.5494\n",
      "Epoch 42/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1129 - acc: 0.9645 - val_loss: 2.9984 - val_acc: 0.5499\n",
      "Epoch 43/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1116 - acc: 0.9641 - val_loss: 2.8358 - val_acc: 0.5654\n",
      "Epoch 44/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.1045 - acc: 0.9658 - val_loss: 2.9524 - val_acc: 0.5529\n",
      "Epoch 45/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1072 - acc: 0.9669 - val_loss: 3.0218 - val_acc: 0.5599\n",
      "Epoch 46/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0863 - acc: 0.9721 - val_loss: 2.8272 - val_acc: 0.5669\n",
      "Epoch 47/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0810 - acc: 0.9725 - val_loss: 2.9550 - val_acc: 0.5788\n",
      "Epoch 48/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0887 - acc: 0.9711 - val_loss: 2.9026 - val_acc: 0.5729\n",
      "Epoch 49/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0835 - acc: 0.9738 - val_loss: 2.8858 - val_acc: 0.5803\n",
      "Epoch 50/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0700 - acc: 0.9793 - val_loss: 2.8852 - val_acc: 0.5699\n",
      "Epoch 51/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0767 - acc: 0.9737 - val_loss: 2.7955 - val_acc: 0.5783\n",
      "Epoch 52/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0766 - acc: 0.9752 - val_loss: 3.0075 - val_acc: 0.5709\n",
      "Epoch 53/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0664 - acc: 0.9774 - val_loss: 3.0806 - val_acc: 0.5624\n",
      "Epoch 54/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0646 - acc: 0.9802 - val_loss: 3.0775 - val_acc: 0.5798\n",
      "Epoch 55/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0659 - acc: 0.9797 - val_loss: 2.9145 - val_acc: 0.5689\n",
      "Epoch 56/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0526 - acc: 0.9835 - val_loss: 2.8786 - val_acc: 0.5813\n",
      "Epoch 57/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0557 - acc: 0.9819 - val_loss: 2.9395 - val_acc: 0.5848\n",
      "Epoch 58/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0447 - acc: 0.9872 - val_loss: 2.9007 - val_acc: 0.5863\n",
      "Epoch 59/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0528 - acc: 0.9836 - val_loss: 3.0733 - val_acc: 0.5694\n",
      "Epoch 60/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0536 - acc: 0.9833 - val_loss: 2.9552 - val_acc: 0.5948\n",
      "Epoch 61/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0503 - acc: 0.9835 - val_loss: 2.8775 - val_acc: 0.5828\n",
      "Epoch 62/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0382 - acc: 0.9880 - val_loss: 3.0644 - val_acc: 0.5803\n",
      "Epoch 63/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0402 - acc: 0.9875 - val_loss: 3.0238 - val_acc: 0.5833\n",
      "Epoch 64/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0471 - acc: 0.9850 - val_loss: 2.9364 - val_acc: 0.5938\n",
      "Epoch 65/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0406 - acc: 0.9865 - val_loss: 2.9497 - val_acc: 0.5913\n",
      "Epoch 66/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0440 - acc: 0.9865 - val_loss: 3.0776 - val_acc: 0.5873\n",
      "Epoch 67/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0390 - acc: 0.9878 - val_loss: 3.0948 - val_acc: 0.5808\n",
      "Epoch 68/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0325 - acc: 0.9886 - val_loss: 3.0032 - val_acc: 0.5948\n",
      "Epoch 69/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0437 - acc: 0.9858 - val_loss: 2.9974 - val_acc: 0.5828\n",
      "Epoch 70/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0400 - acc: 0.9870 - val_loss: 2.9556 - val_acc: 0.5793\n",
      "Epoch 71/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0322 - acc: 0.9893 - val_loss: 2.9877 - val_acc: 0.5873\n",
      "Epoch 72/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0312 - acc: 0.9899 - val_loss: 2.9859 - val_acc: 0.5948\n",
      "Epoch 73/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0350 - acc: 0.9896 - val_loss: 3.0067 - val_acc: 0.5863\n",
      "Epoch 74/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0230 - acc: 0.9927 - val_loss: 2.9729 - val_acc: 0.5943\n",
      "Epoch 75/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0320 - acc: 0.9893 - val_loss: 3.0281 - val_acc: 0.5878\n",
      "Epoch 76/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0290 - acc: 0.9908 - val_loss: 3.0389 - val_acc: 0.5888\n",
      "Epoch 77/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0334 - acc: 0.9895 - val_loss: 2.9585 - val_acc: 0.5983\n",
      "Epoch 78/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0284 - acc: 0.9908 - val_loss: 3.0993 - val_acc: 0.5888\n",
      "Epoch 79/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0293 - acc: 0.9915 - val_loss: 3.1750 - val_acc: 0.5649\n",
      "Epoch 80/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0341 - acc: 0.9892 - val_loss: 3.0544 - val_acc: 0.5858\n",
      "Epoch 81/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0303 - acc: 0.9919 - val_loss: 2.8667 - val_acc: 0.5993\n",
      "Epoch 82/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0255 - acc: 0.9915 - val_loss: 3.0134 - val_acc: 0.5868\n",
      "Epoch 83/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0255 - acc: 0.9916 - val_loss: 3.0940 - val_acc: 0.5863\n",
      "Epoch 84/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0256 - acc: 0.9910 - val_loss: 2.9810 - val_acc: 0.5893\n",
      "Epoch 85/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0237 - acc: 0.9919 - val_loss: 3.0279 - val_acc: 0.5923\n",
      "Epoch 86/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0229 - acc: 0.9925 - val_loss: 3.0322 - val_acc: 0.5883\n",
      "Epoch 87/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0295 - acc: 0.9900 - val_loss: 3.1583 - val_acc: 0.5883\n",
      "Epoch 88/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0207 - acc: 0.9938 - val_loss: 3.1041 - val_acc: 0.5893\n",
      "Epoch 89/100\n",
      "11352/11352 [==============================] - 355s - loss: 0.0152 - acc: 0.9958 - val_loss: 3.0725 - val_acc: 0.6013\n",
      "Epoch 90/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0155 - acc: 0.9948 - val_loss: 3.0125 - val_acc: 0.6043\n",
      "Epoch 91/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0223 - acc: 0.9927 - val_loss: 3.0437 - val_acc: 0.6058\n",
      "Epoch 92/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0180 - acc: 0.9940 - val_loss: 3.2493 - val_acc: 0.5848\n",
      "Epoch 93/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0243 - acc: 0.9932 - val_loss: 2.9877 - val_acc: 0.6048\n",
      "Epoch 94/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0190 - acc: 0.9947 - val_loss: 2.9412 - val_acc: 0.6078\n",
      "Epoch 95/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0225 - acc: 0.9922 - val_loss: 3.0348 - val_acc: 0.5943\n",
      "Epoch 96/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0201 - acc: 0.9936 - val_loss: 3.1080 - val_acc: 0.5888\n",
      "Epoch 97/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0256 - acc: 0.9919 - val_loss: 3.1117 - val_acc: 0.5923\n",
      "Epoch 98/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0200 - acc: 0.9936 - val_loss: 3.0456 - val_acc: 0.6013\n",
      "Epoch 99/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0214 - acc: 0.9932 - val_loss: 3.0527 - val_acc: 0.6068\n",
      "Epoch 100/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0195 - acc: 0.9940 - val_loss: 3.1141 - val_acc: 0.5888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f959fab4910>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001))\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=100,\n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/CNN-H1-fc6-512-110.json', 'w').write(json_string)\n",
    "model.save_weights('models/CNN-H1-fc6-512-110e.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
