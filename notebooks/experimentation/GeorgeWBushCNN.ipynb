{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>George W Bush CNN</h1>\n",
    "\n",
    "<strong>Abstract</strong> Results show high accuracy but this is misleading as all images are being classified as not George W Bush because there are so many more samples of non-George W Bush images.\n",
    "\n",
    "<strong>Purpose</strong>Build a CNN trained to identify George W Bush. He was chosen because of his high number of images, we would like to see how a CNN with a lot of images of a single person performs. George W Bush has 529 images and there are about 5,748 other people with a total of 12,643 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import collections\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0)\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_lfw_path = data_path + 'lfw_cropped/'\n",
    "\n",
    "batch_size = 128\n",
    "nb_epoch = 4\n",
    "img_rows, img_cols = 100, 100\n",
    "test_size_percent = .8\n",
    "validation_split = .2\n",
    "random_discard_percent = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparing Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filenames_separated_from_target(target):\n",
    "    files = []\n",
    "    target_files = []\n",
    "    \n",
    "    for root, dirnames, filenames in os.walk(data_lfw_path):\n",
    "        for dirname in dirnames:\n",
    "                for filename in os.listdir(os.path.join(data_lfw_path, dirname)):\n",
    "                    if filename.endswith(\".jpg\"):\n",
    "                        f = os.path.join(root + dirname, filename)\n",
    "                        if dirname == target:\n",
    "                            target_files.append(f)\n",
    "                        else:\n",
    "                            files.append(f)\n",
    "    return target_files, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_and_test_sets(target_data, data):\n",
    "    data_to_keep = int((1 - random_discard_percent) * len(data))\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    all_data = [(t, 1) for t in target_data] + [(t, 0) for t in data[:data_to_keep]]\n",
    "    np.random.shuffle(all_data)\n",
    "    \n",
    "    test_size = int(test_size_percent * len(all_data))\n",
    "    X_train = np.array([x[0] for x in all_data[:test_size]])\n",
    "    y_train = np.array([x[1] for x in all_data[:test_size]])\n",
    "    X_test = np.array([x[0] for x in all_data[test_size:]])  \n",
    "    y_test = np.array([x[1] for x in all_data[test_size:]])\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_read(f):\n",
    "    return resize(io.imread(f), (img_rows, img_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_files, files = get_filenames_separated_from_target('George_W_Bush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = [image_read(f) for f in files]\n",
    "target_images = [image_read(f) for f in target_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_train_and_test_sets(target_images, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and Testing the CNN</h2>\n",
    "\n",
    "Implementation of VGG-like convnet http://keras.io/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8429 samples, validate on 2108 samples\n",
      "Epoch 1/4\n",
      "8429/8429 [==============================] - 4178s - loss: 0.2084 - acc: 0.9472 - val_loss: 0.1451 - val_acc: 0.9673\n",
      "Epoch 2/4\n",
      "8429/8429 [==============================] - 4140s - loss: 0.1853 - acc: 0.9578 - val_loss: 0.1456 - val_acc: 0.9673\n",
      "Epoch 3/4\n",
      "8429/8429 [==============================] - 4081s - loss: 0.1813 - acc: 0.9578 - val_loss: 0.1448 - val_acc: 0.9673\n",
      "Epoch 4/4\n",
      "8429/8429 [==============================] - 4081s - loss: 0.1825 - acc: 0.9578 - val_loss: 0.1445 - val_acc: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f69eed50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG = Sequential()\n",
    "\n",
    "VGG.add(Convolution2D(32, 3, 3, input_shape=(3, img_rows, img_cols)))\n",
    "VGG.add(Activation('relu'))\n",
    "VGG.add(Convolution2D(32, 3, 3))\n",
    "VGG.add(Activation('relu'))\n",
    "VGG.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "VGG.add(Dropout(0.25))\n",
    "\n",
    "VGG.add(Convolution2D(64, 3, 3))\n",
    "VGG.add(Activation('relu'))\n",
    "VGG.add(Convolution2D(64, 3, 3))\n",
    "VGG.add(Activation('relu'))\n",
    "VGG.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "VGG.add(Dropout(0.25))\n",
    "\n",
    "VGG.add(Flatten())\n",
    "\n",
    "VGG.add(Dense(256))\n",
    "VGG.add(Activation('relu'))\n",
    "VGG.add(Dropout(0.5))\n",
    "\n",
    "VGG.add(Dense(1))\n",
    "VGG.add(Activation('sigmoid'))\n",
    "\n",
    "VGG.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              class_mode='binary')\n",
    "\n",
    "VGG.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, \n",
    "        show_accuracy=True, verbose=1, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - 252s   \n",
      "('Test score:', 0.16841355326958354)\n",
      "('Test accuracy:', 0.96053130929791275)\n"
     ]
    }
   ],
   "source": [
    "score = VGG.evaluate(X_test, y_test, show_accuracy=True, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
