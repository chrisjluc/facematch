{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stacked Auto Encoders Training 7-13-2016 With Noise</h1>\n",
    "\n",
    "Assuming CNN-H1, and the 6 CNNs for the patches have been trained, we can use the weights to get activations for their fc6 layer and train 3 layers of our SAE individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using gpu device 1: GRID K520 (CNMeM is enabled with initial size: 98.0% of memory, CuDNN 3007)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use('gpu1')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Process\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_h1_weight_file = 'CNN-H1_epoch-20_activations'\n",
    "cnn_p1_weight_file = 'CNN-P1_epoch-20_activations'\n",
    "cnn_p2_weight_file = 'CNN-P2_epoch-20_activations'\n",
    "cnn_p3_weight_file = 'CNN-P3_epoch-20_activations'\n",
    "cnn_p4_weight_file = 'CNN-P4_epoch-20_activations'\n",
    "cnn_p5_weight_file = 'CNN-P5_epoch-20_activations'\n",
    "cnn_p6_weight_file = 'CNN-P6_epoch-20_activations'\n",
    "y_train_file = 'y_train_activations'\n",
    "\n",
    "layer_1_size = 2048\n",
    "layer_2_size = 1024\n",
    "layer_3_size = 512\n",
    "\n",
    "validation_split = .15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_activations(file_name):\n",
    "    return np.load('models/' + file_name + '.npy')\n",
    "\n",
    "def save_activations(file_name, activations):\n",
    "    return np.save('models/' + file_name + '.npy', activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_h1_activations = load_activations(cnn_h1_weight_file)\n",
    "cnn_p1_activations = load_activations(cnn_p1_weight_file)\n",
    "cnn_p2_activations = load_activations(cnn_p2_weight_file)\n",
    "cnn_p3_activations = load_activations(cnn_p3_weight_file)\n",
    "cnn_p4_activations = load_activations(cnn_p4_weight_file)\n",
    "cnn_p5_activations = load_activations(cnn_p5_weight_file)\n",
    "cnn_p6_activations = load_activations(cnn_p6_weight_file)\n",
    "y_train = load_activations(y_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_activations(_activations):\n",
    "    return np.array([activation for activations in _activations for activation in activations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_h1_activations = fix_activations(cnn_h1_activations)\n",
    "cnn_p1_activations = fix_activations(cnn_p1_activations)\n",
    "cnn_p2_activations = fix_activations(cnn_p2_activations)\n",
    "cnn_p3_activations = fix_activations(cnn_p3_activations)\n",
    "cnn_p4_activations = fix_activations(cnn_p4_activations)\n",
    "cnn_p5_activations = fix_activations(cnn_p5_activations)\n",
    "cnn_p6_activations = fix_activations(cnn_p6_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26668, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_h1_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activations = np.concatenate((\n",
    "        cnn_h1_activations, \n",
    "        cnn_p1_activations,\n",
    "        cnn_p2_activations,\n",
    "        cnn_p3_activations,\n",
    "        cnn_p4_activations,\n",
    "        cnn_p5_activations,\n",
    "        cnn_p6_activations), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26668, 3584)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26668,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Noise</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_noise(activations, random_threshold, gaussian_scale):\n",
    "    return np.array([np.array([value + np.random.normal(scale=gaussian_scale) \n",
    "                      if np.random.rand() < random_threshold else value\n",
    "                      for value in activation]) for activation in activations])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activations_with_noise_10_1 = random_noise(activations, .1, 1)\n",
    "save_activations('activations_with_noise_10_1', activations_with_noise_10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-7e6cfb3d14d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mactivations_with_noise_05_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-ac9cf6f7f84c>\u001b[0m in \u001b[0;36mrandom_noise\u001b[1;34m(activations, random_threshold, gaussian_scale)\u001b[0m\n\u001b[0;32m      2\u001b[0m     return np.array([np.array([value + np.random.normal(scale=gaussian_scale) \n\u001b[0;32m      3\u001b[0m                       \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mrandom_threshold\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                       for value in activation]) for activation in activations])       \n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activations_with_noise_05_1 = random_noise(activations, .05, 1)\n",
    "save_activations('activations_with_noise_05_1', activations_with_noise_05_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activations_with_noise_20_1 = random_noise(activations, .2, 1)\n",
    "save_activations('activations_with_noise_20_1', activations_with_noise_20_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activations_with_noise_30_1 = random_noise(activations, .3, 1)\n",
    "save_activations('activations_with_noise_30_1', activations_with_noise_30_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auto Encoder</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_encoder(X_train, X_test, encoding_dim, nb_epoch=50, regularizer=10e-5):\n",
    "    assert X_train.shape[1] == X_test.shape[1]\n",
    "    shape = X_train.shape[1]\n",
    "\n",
    "    input_img = Input(shape=(shape,))\n",
    "    encoded = Dense(\n",
    "        encoding_dim, \n",
    "        activation='relu', \n",
    "        activity_regularizer=regularizers.activity_l1(regularizer)\n",
    "    )(input_img)\n",
    "    decoded = Dense(shape, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "    # sgd = SGD(lr=.01, decay=99.9) #lr=0.01->0.00001\n",
    "    autoencoder.compile(\n",
    "        optimizer='adadelta', \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                nb_epoch=nb_epoch,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "    return autoencoder, encoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activations_with_noise = load_activations('activations_with_noise_30_1')\n",
    "\n",
    "x_train = activations_with_noise[:int(activations_with_noise.shape[0] * (1 - validation_split))]\n",
    "x_test = activations_with_noise[int(activations_with_noise.shape[0] * (1 - validation_split)):]\n",
    "X_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "X_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22667 samples, validate on 4001 samples\n",
      "Epoch 1/30\n",
      "22667/22667 [==============================] - 4s - loss: -57973.8529 - acc: 0.0414 - val_loss: -65449.6027 - val_acc: 0.0757\n",
      "Epoch 2/30\n",
      "22667/22667 [==============================] - 4s - loss: -67489.7975 - acc: 0.1147 - val_loss: -68494.9747 - val_acc: 0.1427\n",
      "Epoch 3/30\n",
      "22667/22667 [==============================] - 4s - loss: -69783.4737 - acc: 0.1586 - val_loss: -69821.3545 - val_acc: 0.1617\n",
      "Epoch 4/30\n",
      "22667/22667 [==============================] - 4s - loss: -71011.6880 - acc: 0.1919 - val_loss: -71128.5413 - val_acc: 0.2002\n",
      "Epoch 5/30\n",
      "22667/22667 [==============================] - 4s - loss: -71876.4442 - acc: 0.2160 - val_loss: -71661.0824 - val_acc: 0.2219\n",
      "Epoch 6/30\n",
      "22667/22667 [==============================] - 4s - loss: -72516.0055 - acc: 0.2373 - val_loss: -71997.6701 - val_acc: 0.2362\n",
      "Epoch 7/30\n",
      "22667/22667 [==============================] - 4s - loss: -72986.8669 - acc: 0.2503 - val_loss: -72368.1699 - val_acc: 0.2544\n",
      "Epoch 8/30\n",
      "22667/22667 [==============================] - 4s - loss: -73361.9476 - acc: 0.2604 - val_loss: -73061.5452 - val_acc: 0.2749\n",
      "Epoch 9/30\n",
      "22667/22667 [==============================] - 4s - loss: -73711.5869 - acc: 0.2767 - val_loss: -73074.1560 - val_acc: 0.2817\n",
      "Epoch 10/30\n",
      "22667/22667 [==============================] - 4s - loss: -73966.2162 - acc: 0.2842 - val_loss: -73367.8869 - val_acc: 0.2769\n",
      "Epoch 11/30\n",
      "22667/22667 [==============================] - 4s - loss: -74200.2702 - acc: 0.2924 - val_loss: -73553.7864 - val_acc: 0.2744\n",
      "Epoch 12/30\n",
      "22667/22667 [==============================] - 4s - loss: -74421.8117 - acc: 0.3002 - val_loss: -73922.9575 - val_acc: 0.3042\n",
      "Epoch 13/30\n",
      "22667/22667 [==============================] - 4s - loss: -74618.7914 - acc: 0.3100 - val_loss: -73890.3859 - val_acc: 0.3037\n",
      "Epoch 14/30\n",
      "22667/22667 [==============================] - 4s - loss: -74794.9037 - acc: 0.3143 - val_loss: -74046.6758 - val_acc: 0.3072\n",
      "Epoch 15/30\n",
      "22667/22667 [==============================] - 4s - loss: -74933.4892 - acc: 0.3184 - val_loss: -74402.8093 - val_acc: 0.3127\n",
      "Epoch 16/30\n",
      "22667/22667 [==============================] - 4s - loss: -75090.3988 - acc: 0.3203 - val_loss: -74364.0031 - val_acc: 0.3182\n",
      "Epoch 17/30\n",
      "22667/22667 [==============================] - 4s - loss: -75212.8897 - acc: 0.3273 - val_loss: -74551.5877 - val_acc: 0.3259\n",
      "Epoch 18/30\n",
      "22667/22667 [==============================] - 4s - loss: -75369.7258 - acc: 0.3290 - val_loss: -74663.5409 - val_acc: 0.3287\n",
      "Epoch 19/30\n",
      "22667/22667 [==============================] - 4s - loss: -75434.3223 - acc: 0.3364 - val_loss: -74615.0604 - val_acc: 0.3272\n",
      "Epoch 20/30\n",
      "22667/22667 [==============================] - 4s - loss: -75538.6561 - acc: 0.3417 - val_loss: -74832.3959 - val_acc: 0.3374\n",
      "Epoch 21/30\n",
      "22667/22667 [==============================] - 4s - loss: -75646.9015 - acc: 0.3391 - val_loss: -74904.8440 - val_acc: 0.3327\n",
      "Epoch 22/30\n",
      "22667/22667 [==============================] - 4s - loss: -75738.3181 - acc: 0.3454 - val_loss: -74854.3550 - val_acc: 0.3357\n",
      "Epoch 23/30\n",
      "22667/22667 [==============================] - 4s - loss: -75800.3679 - acc: 0.3444 - val_loss: -75073.1184 - val_acc: 0.3444\n",
      "Epoch 24/30\n",
      "22667/22667 [==============================] - 4s - loss: -75929.7727 - acc: 0.3475 - val_loss: -75237.6394 - val_acc: 0.3499\n",
      "Epoch 25/30\n",
      "22667/22667 [==============================] - 4s - loss: -75941.0113 - acc: 0.3536 - val_loss: -75069.8693 - val_acc: 0.3469\n",
      "Epoch 26/30\n",
      "22667/22667 [==============================] - 4s - loss: -76023.5701 - acc: 0.3518 - val_loss: -75034.8459 - val_acc: 0.3479\n",
      "Epoch 27/30\n",
      "22667/22667 [==============================] - 4s - loss: -76152.7780 - acc: 0.3575 - val_loss: -75031.8181 - val_acc: 0.3527\n",
      "Epoch 28/30\n",
      "22667/22667 [==============================] - 4s - loss: -76138.4665 - acc: 0.3558 - val_loss: -75172.4643 - val_acc: 0.3479\n",
      "Epoch 29/30\n",
      "22667/22667 [==============================] - 4s - loss: -76240.2058 - acc: 0.3566 - val_loss: -75381.5626 - val_acc: 0.3399\n",
      "Epoch 30/30\n",
      "22667/22667 [==============================] - 4s - loss: -76295.7262 - acc: 0.3590 - val_loss: -75402.3826 - val_acc: 0.3587\n"
     ]
    }
   ],
   "source": [
    "autoencoder1, encoder1 = get_encoder(X_train, X_test, 2048, 30, 10e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22667, 2048)\n",
      "(4001, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_train = encoder1.predict(X_train)\n",
    "X_test = encoder1.predict(X_test)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22667 samples, validate on 4001 samples\n",
      "Epoch 1/50\n",
      "22667/22667 [==============================] - 2s - loss: 90460.4151 - acc: 5.2940e-04 - val_loss: 89618.6260 - val_acc: 9.9975e-04\n",
      "Epoch 2/50\n",
      "22667/22667 [==============================] - 2s - loss: 89522.8048 - acc: 0.0012 - val_loss: 88951.2154 - val_acc: 0.0042\n",
      "Epoch 3/50\n",
      "22667/22667 [==============================] - 2s - loss: 88566.5401 - acc: 0.0196 - val_loss: 87696.9567 - val_acc: 0.0835\n",
      "Epoch 4/50\n",
      "22667/22667 [==============================] - 2s - loss: 87095.2562 - acc: 0.1074 - val_loss: 86337.9030 - val_acc: 0.1620\n",
      "Epoch 5/50\n",
      "22667/22667 [==============================] - 2s - loss: 85858.9567 - acc: 0.1735 - val_loss: 85405.2249 - val_acc: 0.2044\n",
      "Epoch 6/50\n",
      "22667/22667 [==============================] - 2s - loss: 84921.3315 - acc: 0.2313 - val_loss: 84788.3799 - val_acc: 0.2442\n",
      "Epoch 7/50\n",
      "22667/22667 [==============================] - 2s - loss: 84267.2766 - acc: 0.2793 - val_loss: 84111.6902 - val_acc: 0.2947\n",
      "Epoch 8/50\n",
      "22667/22667 [==============================] - 2s - loss: 83732.1767 - acc: 0.3190 - val_loss: 83839.9216 - val_acc: 0.3179\n",
      "Epoch 9/50\n",
      "22667/22667 [==============================] - 2s - loss: 83359.8372 - acc: 0.3460 - val_loss: 83433.2947 - val_acc: 0.3584\n",
      "Epoch 10/50\n",
      "22667/22667 [==============================] - 2s - loss: 83047.9580 - acc: 0.3688 - val_loss: 83325.4618 - val_acc: 0.3614\n",
      "Epoch 11/50\n",
      "22667/22667 [==============================] - 2s - loss: 82827.8590 - acc: 0.3855 - val_loss: 82963.6416 - val_acc: 0.4144\n",
      "Epoch 12/50\n",
      "22667/22667 [==============================] - 2s - loss: 82622.2898 - acc: 0.4085 - val_loss: 83060.1784 - val_acc: 0.3932\n",
      "Epoch 13/50\n",
      "22667/22667 [==============================] - 2s - loss: 82490.9935 - acc: 0.4149 - val_loss: 82823.6473 - val_acc: 0.3982\n",
      "Epoch 14/50\n",
      "22667/22667 [==============================] - 2s - loss: 82360.9926 - acc: 0.4278 - val_loss: 82641.2493 - val_acc: 0.4369\n",
      "Epoch 15/50\n",
      "22667/22667 [==============================] - 2s - loss: 82262.2693 - acc: 0.4354 - val_loss: 82493.3526 - val_acc: 0.4409\n",
      "Epoch 16/50\n",
      "22667/22667 [==============================] - 2s - loss: 82164.7002 - acc: 0.4476 - val_loss: 82629.7871 - val_acc: 0.4304\n",
      "Epoch 17/50\n",
      "22667/22667 [==============================] - 2s - loss: 82100.0394 - acc: 0.4502 - val_loss: 82406.6318 - val_acc: 0.4451\n",
      "Epoch 18/50\n",
      "22667/22667 [==============================] - 2s - loss: 82021.7843 - acc: 0.4603 - val_loss: 82489.2501 - val_acc: 0.4594\n",
      "Epoch 19/50\n",
      "22667/22667 [==============================] - 2s - loss: 81972.2525 - acc: 0.4634 - val_loss: 82295.2938 - val_acc: 0.4549\n",
      "Epoch 20/50\n",
      "22667/22667 [==============================] - 2s - loss: 81929.9329 - acc: 0.4680 - val_loss: 82160.7602 - val_acc: 0.4771\n",
      "Epoch 21/50\n",
      "22667/22667 [==============================] - 2s - loss: 81861.7557 - acc: 0.4765 - val_loss: 82257.1815 - val_acc: 0.4724\n",
      "Epoch 22/50\n",
      "22667/22667 [==============================] - 2s - loss: 81843.0622 - acc: 0.4738 - val_loss: 82165.5958 - val_acc: 0.4731\n",
      "Epoch 23/50\n",
      "22667/22667 [==============================] - 2s - loss: 81797.6204 - acc: 0.4826 - val_loss: 82142.2780 - val_acc: 0.4926\n",
      "Epoch 24/50\n",
      "22667/22667 [==============================] - 2s - loss: 81770.1221 - acc: 0.4813 - val_loss: 82191.5733 - val_acc: 0.4871\n",
      "Epoch 25/50\n",
      "22667/22667 [==============================] - 2s - loss: 81724.0185 - acc: 0.4928 - val_loss: 82012.2363 - val_acc: 0.4996\n",
      "Epoch 26/50\n",
      "22667/22667 [==============================] - 2s - loss: 81713.0184 - acc: 0.4922 - val_loss: 82078.4758 - val_acc: 0.4786\n",
      "Epoch 27/50\n",
      "22667/22667 [==============================] - 2s - loss: 81681.1840 - acc: 0.4949 - val_loss: 82026.5644 - val_acc: 0.5156\n",
      "Epoch 28/50\n",
      "22667/22667 [==============================] - 2s - loss: 81658.6369 - acc: 0.4979 - val_loss: 81904.4388 - val_acc: 0.5139\n",
      "Epoch 29/50\n",
      "22667/22667 [==============================] - 2s - loss: 81631.3884 - acc: 0.5032 - val_loss: 81994.0747 - val_acc: 0.5186\n",
      "Epoch 30/50\n",
      "22667/22667 [==============================] - 2s - loss: 81613.7398 - acc: 0.5029 - val_loss: 81899.7037 - val_acc: 0.5059\n",
      "Epoch 31/50\n",
      "22667/22667 [==============================] - 2s - loss: 81613.7071 - acc: 0.5051 - val_loss: 81979.9614 - val_acc: 0.5159\n",
      "Epoch 32/50\n",
      "22667/22667 [==============================] - 2s - loss: 81568.3597 - acc: 0.5130 - val_loss: 81923.1292 - val_acc: 0.5034\n",
      "Epoch 33/50\n",
      "22667/22667 [==============================] - 2s - loss: 81570.2241 - acc: 0.5066 - val_loss: 82072.4914 - val_acc: 0.5111\n",
      "Epoch 34/50\n",
      "22667/22667 [==============================] - 2s - loss: 81548.8441 - acc: 0.5077 - val_loss: 82087.4242 - val_acc: 0.4691\n",
      "Epoch 35/50\n",
      "22667/22667 [==============================] - 2s - loss: 81529.1709 - acc: 0.5139 - val_loss: 81930.1216 - val_acc: 0.5161\n",
      "Epoch 36/50\n",
      "22667/22667 [==============================] - 2s - loss: 81508.3740 - acc: 0.5183 - val_loss: 82107.1252 - val_acc: 0.4889\n",
      "Epoch 37/50\n",
      "22667/22667 [==============================] - 2s - loss: 81500.8251 - acc: 0.5205 - val_loss: 81984.3906 - val_acc: 0.5039\n",
      "Epoch 38/50\n",
      "22667/22667 [==============================] - 2s - loss: 81504.2157 - acc: 0.5126 - val_loss: 81890.7808 - val_acc: 0.5201\n",
      "Epoch 39/50\n",
      "22667/22667 [==============================] - 2s - loss: 81469.1624 - acc: 0.5240 - val_loss: 81898.5958 - val_acc: 0.5289\n",
      "Epoch 40/50\n",
      "22667/22667 [==============================] - 2s - loss: 81461.2126 - acc: 0.5222 - val_loss: 81875.7837 - val_acc: 0.5124\n",
      "Epoch 41/50\n",
      "22667/22667 [==============================] - 2s - loss: 81454.3703 - acc: 0.5246 - val_loss: 81845.2417 - val_acc: 0.5136\n",
      "Epoch 42/50\n",
      "22667/22667 [==============================] - 2s - loss: 81443.2160 - acc: 0.5264 - val_loss: 81937.5461 - val_acc: 0.5089\n",
      "Epoch 43/50\n",
      "22667/22667 [==============================] - 2s - loss: 81437.3140 - acc: 0.5246 - val_loss: 81766.1061 - val_acc: 0.5376\n",
      "Epoch 44/50\n",
      "22667/22667 [==============================] - 2s - loss: 81418.6703 - acc: 0.5305 - val_loss: 81736.3953 - val_acc: 0.5204\n",
      "Epoch 45/50\n",
      "22667/22667 [==============================] - 2s - loss: 81416.7163 - acc: 0.5300 - val_loss: 81985.6091 - val_acc: 0.5089\n",
      "Epoch 46/50\n",
      "22667/22667 [==============================] - 2s - loss: 81409.5502 - acc: 0.5309 - val_loss: 81633.9967 - val_acc: 0.5531\n",
      "Epoch 47/50\n",
      "22667/22667 [==============================] - 2s - loss: 81386.1919 - acc: 0.5299 - val_loss: 81900.0338 - val_acc: 0.5309\n",
      "Epoch 48/50\n",
      "22667/22667 [==============================] - 2s - loss: 81393.3848 - acc: 0.5331 - val_loss: 81638.4295 - val_acc: 0.5534\n",
      "Epoch 49/50\n",
      "22667/22667 [==============================] - 2s - loss: 81374.6666 - acc: 0.5328 - val_loss: 81921.1495 - val_acc: 0.5236\n",
      "Epoch 50/50\n",
      "22667/22667 [==============================] - 2s - loss: 81383.1852 - acc: 0.5285 - val_loss: 81803.2151 - val_acc: 0.5236\n"
     ]
    }
   ],
   "source": [
    "autoencoder2, encoder2 = get_encoder(X_train, X_test, 1024, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22667, 1024)\n",
      "(4001, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = encoder2.predict(X_train)\n",
    "X_test = encoder2.predict(X_test)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22667 samples, validate on 4001 samples\n",
      "Epoch 1/50\n",
      "22667/22667 [==============================] - 1s - loss: 14006.0073 - acc: 0.0018 - val_loss: 13233.2534 - val_acc: 0.0030\n",
      "Epoch 2/50\n",
      "22667/22667 [==============================] - 1s - loss: 13351.1249 - acc: 0.0111 - val_loss: 12676.1877 - val_acc: 0.0637\n",
      "Epoch 3/50\n",
      "22667/22667 [==============================] - 1s - loss: 12740.6037 - acc: 0.2036 - val_loss: 12161.4466 - val_acc: 0.2989\n",
      "Epoch 4/50\n",
      "22667/22667 [==============================] - 1s - loss: 12301.2750 - acc: 0.3122 - val_loss: 11858.5385 - val_acc: 0.3752\n",
      "Epoch 5/50\n",
      "22667/22667 [==============================] - 1s - loss: 12041.9835 - acc: 0.3570 - val_loss: 11706.7873 - val_acc: 0.3962\n",
      "Epoch 6/50\n",
      "22667/22667 [==============================] - 1s - loss: 11866.5490 - acc: 0.3838 - val_loss: 11559.6472 - val_acc: 0.3799\n",
      "Epoch 7/50\n",
      "22667/22667 [==============================] - 1s - loss: 11744.8974 - acc: 0.4015 - val_loss: 11483.6837 - val_acc: 0.3939\n",
      "Epoch 8/50\n",
      "22667/22667 [==============================] - 1s - loss: 11650.0966 - acc: 0.4162 - val_loss: 11408.4855 - val_acc: 0.4266\n",
      "Epoch 9/50\n",
      "22667/22667 [==============================] - 1s - loss: 11579.8699 - acc: 0.4296 - val_loss: 11362.2038 - val_acc: 0.4111\n",
      "Epoch 10/50\n",
      "22667/22667 [==============================] - 1s - loss: 11519.1369 - acc: 0.4412 - val_loss: 11283.4706 - val_acc: 0.4694\n",
      "Epoch 11/50\n",
      "22667/22667 [==============================] - 1s - loss: 11473.0233 - acc: 0.4500 - val_loss: 11274.7711 - val_acc: 0.4834\n",
      "Epoch 12/50\n",
      "22667/22667 [==============================] - 1s - loss: 11427.7021 - acc: 0.4631 - val_loss: 11212.8848 - val_acc: 0.5169\n",
      "Epoch 13/50\n",
      "22667/22667 [==============================] - 1s - loss: 11394.1317 - acc: 0.4757 - val_loss: 11192.0529 - val_acc: 0.4764\n",
      "Epoch 14/50\n",
      "22667/22667 [==============================] - 1s - loss: 11368.2129 - acc: 0.4845 - val_loss: 11157.3119 - val_acc: 0.5041\n",
      "Epoch 15/50\n",
      "22667/22667 [==============================] - 1s - loss: 11342.7156 - acc: 0.4982 - val_loss: 11145.9645 - val_acc: 0.5154\n",
      "Epoch 16/50\n",
      "22667/22667 [==============================] - 1s - loss: 11316.6672 - acc: 0.5076 - val_loss: 11112.9245 - val_acc: 0.5394\n",
      "Epoch 17/50\n",
      "22667/22667 [==============================] - 1s - loss: 11301.2771 - acc: 0.5240 - val_loss: 11103.6403 - val_acc: 0.5414\n",
      "Epoch 18/50\n",
      "22667/22667 [==============================] - 1s - loss: 11281.2173 - acc: 0.5355 - val_loss: 11080.8879 - val_acc: 0.5504\n",
      "Epoch 19/50\n",
      "22667/22667 [==============================] - 1s - loss: 11270.4262 - acc: 0.5413 - val_loss: 11078.7922 - val_acc: 0.5589\n",
      "Epoch 20/50\n",
      "22667/22667 [==============================] - 1s - loss: 11257.0027 - acc: 0.5528 - val_loss: 11076.8596 - val_acc: 0.5619\n",
      "Epoch 21/50\n",
      "22667/22667 [==============================] - 1s - loss: 11243.8620 - acc: 0.5618 - val_loss: 11054.9938 - val_acc: 0.5631\n",
      "Epoch 22/50\n",
      "22667/22667 [==============================] - 1s - loss: 11232.8921 - acc: 0.5689 - val_loss: 11050.3553 - val_acc: 0.5644\n",
      "Epoch 23/50\n",
      "22667/22667 [==============================] - 1s - loss: 11225.8233 - acc: 0.5705 - val_loss: 11059.3758 - val_acc: 0.5716\n",
      "Epoch 24/50\n",
      "22667/22667 [==============================] - 1s - loss: 11217.6888 - acc: 0.5768 - val_loss: 11036.8500 - val_acc: 0.5819\n",
      "Epoch 25/50\n",
      "22667/22667 [==============================] - 1s - loss: 11211.6428 - acc: 0.5840 - val_loss: 11014.8297 - val_acc: 0.6008\n",
      "Epoch 26/50\n",
      "22667/22667 [==============================] - 1s - loss: 11203.9990 - acc: 0.5898 - val_loss: 11001.7576 - val_acc: 0.5984\n",
      "Epoch 27/50\n",
      "22667/22667 [==============================] - 1s - loss: 11200.5795 - acc: 0.5887 - val_loss: 11001.3292 - val_acc: 0.6041\n",
      "Epoch 28/50\n",
      "22667/22667 [==============================] - 1s - loss: 11193.2760 - acc: 0.5934 - val_loss: 11009.9557 - val_acc: 0.6003\n",
      "Epoch 29/50\n",
      "22667/22667 [==============================] - 1s - loss: 11187.1201 - acc: 0.5974 - val_loss: 11024.9663 - val_acc: 0.5869\n",
      "Epoch 30/50\n",
      "22667/22667 [==============================] - 1s - loss: 11185.2183 - acc: 0.5976 - val_loss: 11014.2741 - val_acc: 0.5966\n",
      "Epoch 31/50\n",
      "22667/22667 [==============================] - 1s - loss: 11180.4206 - acc: 0.5971 - val_loss: 10993.7857 - val_acc: 0.6073\n",
      "Epoch 32/50\n",
      "22667/22667 [==============================] - 1s - loss: 11173.2632 - acc: 0.6008 - val_loss: 10988.9088 - val_acc: 0.6068\n",
      "Epoch 33/50\n",
      "22667/22667 [==============================] - 1s - loss: 11172.9336 - acc: 0.6000 - val_loss: 10978.6048 - val_acc: 0.6133\n",
      "Epoch 34/50\n",
      "22667/22667 [==============================] - 1s - loss: 11169.5918 - acc: 0.6016 - val_loss: 11005.1229 - val_acc: 0.6161\n",
      "Epoch 35/50\n",
      "22667/22667 [==============================] - 1s - loss: 11165.5359 - acc: 0.6052 - val_loss: 10958.5695 - val_acc: 0.6186\n",
      "Epoch 36/50\n",
      "22667/22667 [==============================] - 1s - loss: 11163.7775 - acc: 0.6107 - val_loss: 10997.5934 - val_acc: 0.6181\n",
      "Epoch 37/50\n",
      "22667/22667 [==============================] - 1s - loss: 11160.0731 - acc: 0.6089 - val_loss: 10973.4247 - val_acc: 0.6151\n",
      "Epoch 38/50\n",
      "22667/22667 [==============================] - 1s - loss: 11159.0585 - acc: 0.6080 - val_loss: 10971.7495 - val_acc: 0.6213\n",
      "Epoch 39/50\n",
      "22667/22667 [==============================] - 1s - loss: 11153.9485 - acc: 0.6103 - val_loss: 11003.3757 - val_acc: 0.6063\n",
      "Epoch 40/50\n",
      "22667/22667 [==============================] - 1s - loss: 11153.9031 - acc: 0.6112 - val_loss: 10979.9783 - val_acc: 0.6141\n",
      "Epoch 41/50\n",
      "22667/22667 [==============================] - 1s - loss: 11150.3647 - acc: 0.6127 - val_loss: 10988.2778 - val_acc: 0.6041\n",
      "Epoch 42/50\n",
      "22667/22667 [==============================] - 1s - loss: 11147.5940 - acc: 0.6149 - val_loss: 10958.6579 - val_acc: 0.6258\n",
      "Epoch 43/50\n",
      "22667/22667 [==============================] - 1s - loss: 11148.6572 - acc: 0.6107 - val_loss: 10971.5423 - val_acc: 0.6233\n",
      "Epoch 44/50\n",
      "22667/22667 [==============================] - 1s - loss: 11147.8857 - acc: 0.6110 - val_loss: 10971.5987 - val_acc: 0.6281\n",
      "Epoch 45/50\n",
      "22667/22667 [==============================] - 1s - loss: 11144.8703 - acc: 0.6151 - val_loss: 10964.3283 - val_acc: 0.6206\n",
      "Epoch 46/50\n",
      "22667/22667 [==============================] - 1s - loss: 11140.4682 - acc: 0.6157 - val_loss: 10951.4339 - val_acc: 0.6323\n",
      "Epoch 47/50\n",
      "22667/22667 [==============================] - 1s - loss: 11140.2015 - acc: 0.6170 - val_loss: 10983.8926 - val_acc: 0.6046\n",
      "Epoch 48/50\n",
      "22667/22667 [==============================] - 1s - loss: 11140.4065 - acc: 0.6163 - val_loss: 10966.9046 - val_acc: 0.6191\n",
      "Epoch 49/50\n",
      "22667/22667 [==============================] - 1s - loss: 11136.4986 - acc: 0.6147 - val_loss: 10950.8365 - val_acc: 0.6243\n",
      "Epoch 50/50\n",
      "22667/22667 [==============================] - 1s - loss: 11137.5934 - acc: 0.6186 - val_loss: 10952.0466 - val_acc: 0.6308\n"
     ]
    }
   ],
   "source": [
    "autoencoder3, encoder3 = get_encoder(X_train, X_test, 512, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22667, 512)\n",
      "(4001, 512)\n"
     ]
    }
   ],
   "source": [
    "X_train = encoder3.predict(X_train)\n",
    "X_test = encoder3.predict(X_test)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
