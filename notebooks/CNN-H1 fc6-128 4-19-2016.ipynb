{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN-H1 4-19-2016</h1>\n",
    "\n",
    "<strong>Abstract</strong>\n",
    "Implementing the CNN-H1 using NN2 described in the paper: http://arxiv.org/pdf/1509.00244v1.pdf. \n",
    "\n",
    "<strong>Improvements</strong>\n",
    "<ul>\n",
    "<li>Narrowed the width of faces to focus on the face, cut out background</li>\n",
    "<li>Validation split of 15%</li>\n",
    "<li>fc6 layer has a length of 128</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 98.0% of memory, CuDNN 3007)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/lfw_cropped'\n",
    "\n",
    "img_rows_load, img_cols_load = 160, 160\n",
    "img_rows, img_cols = 160, 120\n",
    "num_people = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading Files</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_path_dict():\n",
    "    face_to_file_paths_dict = {}\n",
    "    \n",
    "    for root, dirnames, filenames in os.walk(data_path):\n",
    "        for dirname in dirnames:\n",
    "            if dirname not in face_to_file_paths_dict:\n",
    "                face_to_file_paths_dict[dirname] = []\n",
    "            directory_path = os.path.join(data_path, dirname)\n",
    "            for filename in os.listdir(directory_path):\n",
    "                if filename.endswith(\".jpg\"):\n",
    "                    face_to_file_paths_dict[dirname].append(os.path.join(directory_path, filename))\n",
    "                            \n",
    "    return face_to_file_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_paths_descending_list(face_to_file_paths_dict):\n",
    "    return sorted(face_to_file_paths_dict.items(), key=lambda x: len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_dict = get_face_to_file_path_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_list = get_face_to_file_paths_descending_list(face_to_file_paths_dict)[:num_people]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Pre-Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_read(f):\n",
    "    return resize(rgb2grey(io.imread(f)), (img_rows_load, img_cols_load))\n",
    "\n",
    "def reflection(image):\n",
    "    return np.array([list(reversed(row)) for row in image])\n",
    "\n",
    "def partition(image, top_left, rows, cols):\n",
    "    return np.array([row[top_left[1]:top_left[1] + cols] for row in image[top_left[0]:top_left[0] + rows]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_by_class = [[image_read(f) for f in x[1]] for x in face_to_file_paths_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_by_class)):\n",
    "    images_by_class[i] += [reflection(im) for im in images_by_class[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_by_class)):\n",
    "    images_by_class[i] = [partition(im, (0, 20), img_rows, img_cols) for im in images_by_class[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([image for images in images_by_class for image in images])\n",
    "y_train = np.array([images[0] for images in enumerate(images_by_class) for image in images[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipped = np.array(zip(X_train, y_train))\n",
    "np.random.shuffle(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([x[0] for x in zipped])\n",
    "y_train = np.array([x[1] for x in zipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "Y_train = np_utils.to_categorical(y_train, len(images_by_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training and Validation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN2(input_shape, nb_classes, nb_fc6):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 4\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 5\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(AveragePooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(nb_fc6))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (1, img_rows, img_cols)\n",
    "nb_fc6 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11352 samples, validate on 2004 samples\n",
      "Epoch 1/10\n",
      "11352/11352 [==============================] - 354s - loss: 6.0091 - acc: 0.0750 - val_loss: 5.8350 - val_acc: 0.0843\n",
      "Epoch 2/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.8082 - acc: 0.0782 - val_loss: 5.7898 - val_acc: 0.0843\n",
      "Epoch 3/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.7664 - acc: 0.0775 - val_loss: 5.7692 - val_acc: 0.0843\n",
      "Epoch 4/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.7508 - acc: 0.0785 - val_loss: 5.7761 - val_acc: 0.0843\n",
      "Epoch 5/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.7407 - acc: 0.0783 - val_loss: 5.8062 - val_acc: 0.0843\n",
      "Epoch 6/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.7246 - acc: 0.0783 - val_loss: 5.7389 - val_acc: 0.0843\n",
      "Epoch 7/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.6958 - acc: 0.0782 - val_loss: 5.6843 - val_acc: 0.0843\n",
      "Epoch 8/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.6472 - acc: 0.0800 - val_loss: 5.6296 - val_acc: 0.0848\n",
      "Epoch 9/10\n",
      "11352/11352 [==============================] - 353s - loss: 5.5457 - acc: 0.0872 - val_loss: 5.4803 - val_acc: 0.0958\n",
      "Epoch 10/10\n",
      "11352/11352 [==============================] - 354s - loss: 5.3598 - acc: 0.1158 - val_loss: 5.4299 - val_acc: 0.0973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6bcda42750>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN2(input_shape, num_people, nb_fc6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, \n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/CNN-H1-fc6-128-10e.json', 'w').write(json_string)\n",
    "model.save_weights('models/CNN-H1-fc6-128-10e.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11352 samples, validate on 2004 samples\n",
      "Epoch 1/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.9456 - acc: 0.1759 - val_loss: 5.0023 - val_acc: 0.1881\n",
      "Epoch 2/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.7977 - acc: 0.1958 - val_loss: 4.9032 - val_acc: 0.2006\n",
      "Epoch 3/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.7062 - acc: 0.2052 - val_loss: 4.8093 - val_acc: 0.2081\n",
      "Epoch 4/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.5967 - acc: 0.2179 - val_loss: 4.7832 - val_acc: 0.2196\n",
      "Epoch 5/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.5032 - acc: 0.2253 - val_loss: 4.6240 - val_acc: 0.2360\n",
      "Epoch 6/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.3814 - acc: 0.2445 - val_loss: 4.5420 - val_acc: 0.2445\n",
      "Epoch 7/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.2613 - acc: 0.2557 - val_loss: 4.5127 - val_acc: 0.2485\n",
      "Epoch 8/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.1384 - acc: 0.2668 - val_loss: 4.3467 - val_acc: 0.2600\n",
      "Epoch 9/100\n",
      "11352/11352 [==============================] - 354s - loss: 4.0129 - acc: 0.2807 - val_loss: 4.3027 - val_acc: 0.2705\n",
      "Epoch 10/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.9036 - acc: 0.2946 - val_loss: 4.1696 - val_acc: 0.2829\n",
      "Epoch 11/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.7508 - acc: 0.3104 - val_loss: 4.0442 - val_acc: 0.2954\n",
      "Epoch 12/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.6242 - acc: 0.3292 - val_loss: 3.9542 - val_acc: 0.3139\n",
      "Epoch 13/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.4723 - acc: 0.3475 - val_loss: 3.9102 - val_acc: 0.3069\n",
      "Epoch 14/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.3224 - acc: 0.3661 - val_loss: 3.7382 - val_acc: 0.3249\n",
      "Epoch 15/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.1936 - acc: 0.3819 - val_loss: 3.6408 - val_acc: 0.3433\n",
      "Epoch 16/100\n",
      "11352/11352 [==============================] - 354s - loss: 3.0212 - acc: 0.4047 - val_loss: 3.5764 - val_acc: 0.3498\n",
      "Epoch 17/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.8898 - acc: 0.4189 - val_loss: 3.4563 - val_acc: 0.3623\n",
      "Epoch 18/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.7283 - acc: 0.4388 - val_loss: 3.4133 - val_acc: 0.3787\n",
      "Epoch 19/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.5589 - acc: 0.4646 - val_loss: 3.2428 - val_acc: 0.3857\n",
      "Epoch 20/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.4106 - acc: 0.4944 - val_loss: 3.2927 - val_acc: 0.3842\n",
      "Epoch 21/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.2581 - acc: 0.5125 - val_loss: 3.0629 - val_acc: 0.4147\n",
      "Epoch 22/100\n",
      "11352/11352 [==============================] - 354s - loss: 2.1091 - acc: 0.5338 - val_loss: 3.0564 - val_acc: 0.4087\n",
      "Epoch 23/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.9610 - acc: 0.5574 - val_loss: 2.9660 - val_acc: 0.4276\n",
      "Epoch 24/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.8178 - acc: 0.5859 - val_loss: 2.9220 - val_acc: 0.4286\n",
      "Epoch 25/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.6662 - acc: 0.6083 - val_loss: 2.8949 - val_acc: 0.4456\n",
      "Epoch 26/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.5412 - acc: 0.6293 - val_loss: 2.8842 - val_acc: 0.4461\n",
      "Epoch 27/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.3852 - acc: 0.6596 - val_loss: 2.9019 - val_acc: 0.4436\n",
      "Epoch 28/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.2853 - acc: 0.6830 - val_loss: 2.6278 - val_acc: 0.4800\n",
      "Epoch 29/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.1482 - acc: 0.7110 - val_loss: 2.6815 - val_acc: 0.4780\n",
      "Epoch 30/100\n",
      "11352/11352 [==============================] - 354s - loss: 1.0364 - acc: 0.7330 - val_loss: 2.7120 - val_acc: 0.4800\n",
      "Epoch 31/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.9366 - acc: 0.7484 - val_loss: 2.6374 - val_acc: 0.4855\n",
      "Epoch 32/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.8260 - acc: 0.7782 - val_loss: 2.5973 - val_acc: 0.5055\n",
      "Epoch 33/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.7280 - acc: 0.7952 - val_loss: 2.8521 - val_acc: 0.4736\n",
      "Epoch 34/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.6653 - acc: 0.8135 - val_loss: 2.5304 - val_acc: 0.5210\n",
      "Epoch 35/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.5797 - acc: 0.8391 - val_loss: 2.5942 - val_acc: 0.5165\n",
      "Epoch 36/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.5081 - acc: 0.8522 - val_loss: 2.5915 - val_acc: 0.5205\n",
      "Epoch 37/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.4674 - acc: 0.8674 - val_loss: 2.5466 - val_acc: 0.5454\n",
      "Epoch 38/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.4021 - acc: 0.8816 - val_loss: 3.1514 - val_acc: 0.4456\n",
      "Epoch 39/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.3439 - acc: 0.8953 - val_loss: 2.7203 - val_acc: 0.5329\n",
      "Epoch 40/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.3244 - acc: 0.9001 - val_loss: 2.6047 - val_acc: 0.5624\n",
      "Epoch 41/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2937 - acc: 0.9108 - val_loss: 2.8076 - val_acc: 0.5384\n",
      "Epoch 42/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2682 - acc: 0.9172 - val_loss: 2.6230 - val_acc: 0.5584\n",
      "Epoch 43/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2267 - acc: 0.9304 - val_loss: 2.6708 - val_acc: 0.5489\n",
      "Epoch 44/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.2132 - acc: 0.9341 - val_loss: 2.7564 - val_acc: 0.5554\n",
      "Epoch 45/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1951 - acc: 0.9403 - val_loss: 2.5590 - val_acc: 0.5758\n",
      "Epoch 46/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1795 - acc: 0.9422 - val_loss: 2.6200 - val_acc: 0.5649\n",
      "Epoch 47/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1730 - acc: 0.9470 - val_loss: 2.6373 - val_acc: 0.5753\n",
      "Epoch 48/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1512 - acc: 0.9539 - val_loss: 2.6604 - val_acc: 0.5758\n",
      "Epoch 49/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1430 - acc: 0.9544 - val_loss: 2.6890 - val_acc: 0.5724\n",
      "Epoch 50/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1160 - acc: 0.9649 - val_loss: 2.6614 - val_acc: 0.5788\n",
      "Epoch 51/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1195 - acc: 0.9617 - val_loss: 2.6350 - val_acc: 0.5863\n",
      "Epoch 52/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1100 - acc: 0.9638 - val_loss: 2.6677 - val_acc: 0.5833\n",
      "Epoch 53/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1115 - acc: 0.9656 - val_loss: 2.7620 - val_acc: 0.5833\n",
      "Epoch 54/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.1083 - acc: 0.9657 - val_loss: 2.6809 - val_acc: 0.5828\n",
      "Epoch 55/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0945 - acc: 0.9704 - val_loss: 2.7360 - val_acc: 0.5868\n",
      "Epoch 56/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0949 - acc: 0.9701 - val_loss: 2.7181 - val_acc: 0.5724\n",
      "Epoch 57/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0838 - acc: 0.9744 - val_loss: 2.7035 - val_acc: 0.5828\n",
      "Epoch 58/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0732 - acc: 0.9760 - val_loss: 2.6830 - val_acc: 0.6013\n",
      "Epoch 59/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0762 - acc: 0.9753 - val_loss: 2.6473 - val_acc: 0.6028\n",
      "Epoch 60/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0759 - acc: 0.9767 - val_loss: 2.7132 - val_acc: 0.5963\n",
      "Epoch 61/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0700 - acc: 0.9769 - val_loss: 2.5971 - val_acc: 0.6003\n",
      "Epoch 62/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0497 - acc: 0.9833 - val_loss: 2.9378 - val_acc: 0.5778\n",
      "Epoch 63/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0691 - acc: 0.9775 - val_loss: 2.6983 - val_acc: 0.6068\n",
      "Epoch 64/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0690 - acc: 0.9780 - val_loss: 2.5830 - val_acc: 0.6143\n",
      "Epoch 65/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0557 - acc: 0.9830 - val_loss: 2.7485 - val_acc: 0.6073\n",
      "Epoch 66/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0492 - acc: 0.9841 - val_loss: 2.6937 - val_acc: 0.5983\n",
      "Epoch 67/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0508 - acc: 0.9852 - val_loss: 2.6951 - val_acc: 0.6073\n",
      "Epoch 68/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0411 - acc: 0.9863 - val_loss: 2.6970 - val_acc: 0.6088\n",
      "Epoch 69/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0418 - acc: 0.9881 - val_loss: 2.7299 - val_acc: 0.6058\n",
      "Epoch 70/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0481 - acc: 0.9841 - val_loss: 2.8206 - val_acc: 0.5918\n",
      "Epoch 71/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0444 - acc: 0.9856 - val_loss: 2.7116 - val_acc: 0.6043\n",
      "Epoch 72/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0390 - acc: 0.9867 - val_loss: 2.7640 - val_acc: 0.6043\n",
      "Epoch 73/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0397 - acc: 0.9863 - val_loss: 2.8601 - val_acc: 0.6023\n",
      "Epoch 74/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0388 - acc: 0.9876 - val_loss: 2.6861 - val_acc: 0.6128\n",
      "Epoch 75/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0409 - acc: 0.9878 - val_loss: 2.7187 - val_acc: 0.6178\n",
      "Epoch 76/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0389 - acc: 0.9869 - val_loss: 2.7577 - val_acc: 0.6138\n",
      "Epoch 77/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0375 - acc: 0.9890 - val_loss: 2.7165 - val_acc: 0.6158\n",
      "Epoch 78/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0349 - acc: 0.9895 - val_loss: 2.8332 - val_acc: 0.6088\n",
      "Epoch 79/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0409 - acc: 0.9868 - val_loss: 2.9304 - val_acc: 0.5958\n",
      "Epoch 80/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0426 - acc: 0.9869 - val_loss: 2.7683 - val_acc: 0.6053\n",
      "Epoch 81/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0417 - acc: 0.9871 - val_loss: 2.7100 - val_acc: 0.6188\n",
      "Epoch 82/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0345 - acc: 0.9890 - val_loss: 2.7049 - val_acc: 0.6138\n",
      "Epoch 83/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0329 - acc: 0.9900 - val_loss: 2.6544 - val_acc: 0.6257\n",
      "Epoch 84/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0322 - acc: 0.9892 - val_loss: 2.6721 - val_acc: 0.6248\n",
      "Epoch 85/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0278 - acc: 0.9912 - val_loss: 2.7523 - val_acc: 0.6078\n",
      "Epoch 86/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0248 - acc: 0.9924 - val_loss: 2.7405 - val_acc: 0.6243\n",
      "Epoch 87/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0303 - acc: 0.9912 - val_loss: 2.7117 - val_acc: 0.6282\n",
      "Epoch 88/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0347 - acc: 0.9882 - val_loss: 2.6718 - val_acc: 0.6238\n",
      "Epoch 89/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0329 - acc: 0.9887 - val_loss: 2.7197 - val_acc: 0.6103\n",
      "Epoch 90/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0282 - acc: 0.9909 - val_loss: 2.7510 - val_acc: 0.6198\n",
      "Epoch 91/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0313 - acc: 0.9897 - val_loss: 2.7843 - val_acc: 0.6138\n",
      "Epoch 92/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0288 - acc: 0.9903 - val_loss: 2.7565 - val_acc: 0.6228\n",
      "Epoch 93/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0266 - acc: 0.9910 - val_loss: 2.7148 - val_acc: 0.6287\n",
      "Epoch 94/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0262 - acc: 0.9915 - val_loss: 2.6202 - val_acc: 0.6317\n",
      "Epoch 95/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0211 - acc: 0.9937 - val_loss: 2.6065 - val_acc: 0.6297\n",
      "Epoch 96/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0289 - acc: 0.9915 - val_loss: 2.9017 - val_acc: 0.6108\n",
      "Epoch 97/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0228 - acc: 0.9920 - val_loss: 2.7598 - val_acc: 0.6183\n",
      "Epoch 98/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0190 - acc: 0.9937 - val_loss: 2.7964 - val_acc: 0.6203\n",
      "Epoch 99/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0149 - acc: 0.9953 - val_loss: 2.7626 - val_acc: 0.6193\n",
      "Epoch 100/100\n",
      "11352/11352 [==============================] - 354s - loss: 0.0171 - acc: 0.9955 - val_loss: 2.7006 - val_acc: 0.6292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6aeb6a9690>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001))\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=100,\n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/CNN-H1-fc6-128-110.json', 'w').write(json_string)\n",
    "model.save_weights('models/CNN-H1-fc6-128-110e.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
