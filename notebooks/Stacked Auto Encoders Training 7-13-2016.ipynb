{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stacked Auto Encoders Training 7-13-2016</h1>\n",
    "\n",
    "Assuming CNN-H1, and the 6 CNNs for the patches have been trained, we can use the weights to get activations for their fc6 layer and train 3 layers of our SAE individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 98.0% of memory, CuDNN 3007)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use('gpu0')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Process\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_h1_weight_file = 'CNN-H1_epoch-20_activations'\n",
    "cnn_p1_weight_file = 'CNN-P1_epoch-20_activations'\n",
    "cnn_p2_weight_file = 'CNN-P2_epoch-20_activations'\n",
    "cnn_p3_weight_file = 'CNN-P3_epoch-20_activations'\n",
    "cnn_p4_weight_file = 'CNN-P4_epoch-20_activations'\n",
    "cnn_p5_weight_file = 'CNN-P5_epoch-20_activations'\n",
    "cnn_p6_weight_file = 'CNN-P6_epoch-20_activations'\n",
    "y_train_file = 'y_train_activations'\n",
    "\n",
    "layer_1_size = 2048\n",
    "layer_2_size = 1024\n",
    "layer_3_size = 512\n",
    "\n",
    "validation_split = .15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_activations(file_name):\n",
    "    return np.load('models/' + file_name + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_h1_activations = load_activations(cnn_h1_weight_file)\n",
    "cnn_p1_activations = load_activations(cnn_p1_weight_file)\n",
    "cnn_p2_activations = load_activations(cnn_p2_weight_file)\n",
    "cnn_p3_activations = load_activations(cnn_p3_weight_file)\n",
    "cnn_p4_activations = load_activations(cnn_p4_weight_file)\n",
    "cnn_p5_activations = load_activations(cnn_p5_weight_file)\n",
    "cnn_p6_activations = load_activations(cnn_p6_weight_file)\n",
    "y_train = load_activations(y_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_activations(_activations):\n",
    "    return np.array([activation for activations in _activations for activation in activations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_h1_activations = fix_activations(cnn_h1_activations)\n",
    "cnn_p1_activations = fix_activations(cnn_p1_activations)\n",
    "cnn_p2_activations = fix_activations(cnn_p2_activations)\n",
    "cnn_p3_activations = fix_activations(cnn_p3_activations)\n",
    "cnn_p4_activations = fix_activations(cnn_p4_activations)\n",
    "cnn_p5_activations = fix_activations(cnn_p5_activations)\n",
    "cnn_p6_activations = fix_activations(cnn_p6_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26668, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_h1_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activations = np.concatenate((\n",
    "        cnn_h1_activations, \n",
    "        cnn_p1_activations,\n",
    "        cnn_p2_activations,\n",
    "        cnn_p3_activations,\n",
    "        cnn_p4_activations,\n",
    "        cnn_p5_activations,\n",
    "        cnn_p6_activations), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26668, 3584)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26668,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auto Encoder</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_encoder(X_train, X_test, encoding_dim, nb_epoch=50, regularizer=10e-5):\n",
    "    assert X_train.shape[1] == X_test.shape[1]\n",
    "    shape = X_train.shape[1]\n",
    "\n",
    "    input_img = Input(shape=(shape,))\n",
    "    encoded = Dense(\n",
    "        encoding_dim, \n",
    "        activation='relu', \n",
    "        activity_regularizer=regularizers.activity_l2(regularizer)\n",
    "    )(input_img)\n",
    "    decoded = Dense(shape, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "    # sgd = SGD(lr=.01, decay=99.9) #lr=0.01->0.00001\n",
    "    autoencoder.compile(\n",
    "        optimizer='adadelta', \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                nb_epoch=nb_epoch,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "    return autoencoder, encoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = activations[:int(activations.shape[0] * (1 - validation_split))]\n",
    "x_test = activations[int(activations.shape[0] * (1 - validation_split)):]\n",
    "X_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "X_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22667 samples, validate on 4001 samples\n",
      "Epoch 1/30\n",
      "22667/22667 [==============================] - 4s - loss: -57218.2613 - acc: 0.0609 - val_loss: -66095.6572 - val_acc: 0.1027\n",
      "Epoch 2/30\n",
      "22667/22667 [==============================] - 4s - loss: -66930.3240 - acc: 0.1424 - val_loss: -68691.4351 - val_acc: 0.1612\n",
      "Epoch 3/30\n",
      "22667/22667 [==============================] - 4s - loss: -69162.9925 - acc: 0.1875 - val_loss: -70336.9225 - val_acc: 0.1857\n",
      "Epoch 4/30\n",
      "22667/22667 [==============================] - 4s - loss: -70396.5857 - acc: 0.2150 - val_loss: -71400.6475 - val_acc: 0.2219\n",
      "Epoch 5/30\n",
      "22667/22667 [==============================] - 4s - loss: -71273.8733 - acc: 0.2389 - val_loss: -71893.4412 - val_acc: 0.2447\n",
      "Epoch 6/30\n",
      "22667/22667 [==============================] - 4s - loss: -71922.7869 - acc: 0.2578 - val_loss: -72551.2002 - val_acc: 0.2537\n",
      "Epoch 7/30\n",
      "22667/22667 [==============================] - 4s - loss: -72390.3669 - acc: 0.2709 - val_loss: -72801.4965 - val_acc: 0.2737\n",
      "Epoch 8/30\n",
      "22667/22667 [==============================] - 4s - loss: -72829.6560 - acc: 0.2802 - val_loss: -73175.9105 - val_acc: 0.2927\n",
      "Epoch 9/30\n",
      "22667/22667 [==============================] - 4s - loss: -73168.2158 - acc: 0.2956 - val_loss: -73285.7744 - val_acc: 0.3027\n",
      "Epoch 10/30\n",
      "22667/22667 [==============================] - 4s - loss: -73480.8406 - acc: 0.3028 - val_loss: -73685.8971 - val_acc: 0.3129\n",
      "Epoch 11/30\n",
      "22667/22667 [==============================] - 4s - loss: -73705.0196 - acc: 0.3078 - val_loss: -73892.0462 - val_acc: 0.2954\n",
      "Epoch 12/30\n",
      "22667/22667 [==============================] - 4s - loss: -73937.7839 - acc: 0.3173 - val_loss: -73961.8845 - val_acc: 0.3197\n",
      "Epoch 13/30\n",
      "22667/22667 [==============================] - 4s - loss: -74142.7498 - acc: 0.3199 - val_loss: -74174.2268 - val_acc: 0.3247\n",
      "Epoch 14/30\n",
      "22667/22667 [==============================] - 4s - loss: -74301.4594 - acc: 0.3206 - val_loss: -74270.7078 - val_acc: 0.3244\n",
      "Epoch 15/30\n",
      "22667/22667 [==============================] - 4s - loss: -74488.1283 - acc: 0.3321 - val_loss: -74296.5099 - val_acc: 0.3214\n",
      "Epoch 16/30\n",
      "22667/22667 [==============================] - 4s - loss: -74603.1890 - acc: 0.3365 - val_loss: -74340.6845 - val_acc: 0.3354\n",
      "Epoch 17/30\n",
      "22667/22667 [==============================] - 4s - loss: -74742.7468 - acc: 0.3357 - val_loss: -74569.2877 - val_acc: 0.3134\n",
      "Epoch 18/30\n",
      "22667/22667 [==============================] - 4s - loss: -74869.2495 - acc: 0.3424 - val_loss: -74641.7880 - val_acc: 0.3297\n",
      "Epoch 19/30\n",
      "22667/22667 [==============================] - 4s - loss: -74988.8200 - acc: 0.3416 - val_loss: -74400.1639 - val_acc: 0.3244\n",
      "Epoch 20/30\n",
      "22667/22667 [==============================] - 4s - loss: -75062.0519 - acc: 0.3443 - val_loss: -74583.9684 - val_acc: 0.3284\n",
      "Epoch 21/30\n",
      "22667/22667 [==============================] - 4s - loss: -75206.3524 - acc: 0.3469 - val_loss: -74731.4007 - val_acc: 0.3304\n",
      "Epoch 22/30\n",
      "22667/22667 [==============================] - 4s - loss: -75288.1231 - acc: 0.3520 - val_loss: -74853.2839 - val_acc: 0.3292\n",
      "Epoch 23/30\n",
      "22667/22667 [==============================] - 4s - loss: -75342.3783 - acc: 0.3529 - val_loss: -74858.4668 - val_acc: 0.3344\n",
      "Epoch 24/30\n",
      "22667/22667 [==============================] - 4s - loss: -75429.7445 - acc: 0.3524 - val_loss: -75096.0564 - val_acc: 0.3537\n",
      "Epoch 25/30\n",
      "22667/22667 [==============================] - 4s - loss: -75516.4778 - acc: 0.3526 - val_loss: -75062.8244 - val_acc: 0.3294\n",
      "Epoch 26/30\n",
      "22667/22667 [==============================] - 4s - loss: -75565.1610 - acc: 0.3574 - val_loss: -75211.4317 - val_acc: 0.3414\n",
      "Epoch 27/30\n",
      "22667/22667 [==============================] - 4s - loss: -75649.6465 - acc: 0.3588 - val_loss: -75341.1262 - val_acc: 0.3474\n",
      "Epoch 28/30\n",
      "22667/22667 [==============================] - 4s - loss: -75722.9336 - acc: 0.3599 - val_loss: -74939.2116 - val_acc: 0.3477\n",
      "Epoch 29/30\n",
      "22667/22667 [==============================] - 4s - loss: -75761.7241 - acc: 0.3625 - val_loss: -75290.5813 - val_acc: 0.3477\n",
      "Epoch 30/30\n",
      "22667/22667 [==============================] - 4s - loss: -75800.2958 - acc: 0.3617 - val_loss: -75302.2499 - val_acc: 0.3547\n"
     ]
    }
   ],
   "source": [
    "autoencoder1, encoder1 = get_encoder(X_train, X_test, 2048, 30, 10e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py:514: UserWarning: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 1 is not part of the computational graph needed to compute the outputs: keras_learning_phase.\n",
      "To make this warning into an error, you can pass the parameter on_unused_input='raise' to theano.function. To disable it completely, use on_unused_input='ignore'.\n",
      "  **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22667, 2048)\n",
      "(4001, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_train = encoder1.predict(X_train)\n",
    "X_test = encoder1.predict(X_test)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22667 samples, validate on 4001 samples\n",
      "Epoch 1/50\n",
      "22667/22667 [==============================] - 2s - loss: 41507.4702 - acc: 0.0097 - val_loss: 40334.3564 - val_acc: 0.0575\n",
      "Epoch 2/50\n",
      "22667/22667 [==============================] - 2s - loss: 40034.2114 - acc: 0.1081 - val_loss: 39333.6829 - val_acc: 0.1515\n",
      "Epoch 3/50\n",
      "22667/22667 [==============================] - 2s - loss: 39175.0917 - acc: 0.1829 - val_loss: 38768.4483 - val_acc: 0.2052\n",
      "Epoch 4/50\n",
      "22667/22667 [==============================] - 2s - loss: 38576.8261 - acc: 0.2334 - val_loss: 38230.3148 - val_acc: 0.2599\n",
      "Epoch 5/50\n",
      "22667/22667 [==============================] - 2s - loss: 38140.7666 - acc: 0.2760 - val_loss: 38006.1731 - val_acc: 0.3002\n",
      "Epoch 6/50\n",
      "22667/22667 [==============================] - 2s - loss: 37807.2105 - acc: 0.3141 - val_loss: 37669.6898 - val_acc: 0.3289\n",
      "Epoch 7/50\n",
      "22667/22667 [==============================] - 2s - loss: 37562.8501 - acc: 0.3386 - val_loss: 37510.3859 - val_acc: 0.3502\n",
      "Epoch 8/50\n",
      "22667/22667 [==============================] - 2s - loss: 37375.4694 - acc: 0.3576 - val_loss: 37393.0213 - val_acc: 0.3724\n",
      "Epoch 9/50\n",
      "22667/22667 [==============================] - 2s - loss: 37234.4262 - acc: 0.3731 - val_loss: 37299.0542 - val_acc: 0.3712\n",
      "Epoch 10/50\n",
      "22667/22667 [==============================] - 2s - loss: 37115.9889 - acc: 0.3873 - val_loss: 37133.8333 - val_acc: 0.4056\n",
      "Epoch 11/50\n",
      "22667/22667 [==============================] - 2s - loss: 37023.7983 - acc: 0.3981 - val_loss: 37056.3160 - val_acc: 0.4151\n",
      "Epoch 12/50\n",
      "22667/22667 [==============================] - 2s - loss: 36950.5758 - acc: 0.4081 - val_loss: 37058.7562 - val_acc: 0.4069\n",
      "Epoch 13/50\n",
      "22667/22667 [==============================] - 2s - loss: 36886.5226 - acc: 0.4135 - val_loss: 36997.5982 - val_acc: 0.4194\n",
      "Epoch 14/50\n",
      "22667/22667 [==============================] - 2s - loss: 36840.3933 - acc: 0.4214 - val_loss: 36993.8660 - val_acc: 0.4274\n",
      "Epoch 15/50\n",
      "22667/22667 [==============================] - 2s - loss: 36791.8732 - acc: 0.4319 - val_loss: 36884.8852 - val_acc: 0.4384\n",
      "Epoch 16/50\n",
      "22667/22667 [==============================] - 2s - loss: 36760.1018 - acc: 0.4324 - val_loss: 36874.0233 - val_acc: 0.4514\n",
      "Epoch 17/50\n",
      "22667/22667 [==============================] - 2s - loss: 36718.6611 - acc: 0.4398 - val_loss: 36831.8602 - val_acc: 0.4556\n",
      "Epoch 18/50\n",
      "22667/22667 [==============================] - 2s - loss: 36692.9128 - acc: 0.4443 - val_loss: 36836.9505 - val_acc: 0.4519\n",
      "Epoch 19/50\n",
      "22667/22667 [==============================] - 2s - loss: 36669.0613 - acc: 0.4457 - val_loss: 36780.9816 - val_acc: 0.4606\n",
      "Epoch 20/50\n",
      "22667/22667 [==============================] - 2s - loss: 36645.8388 - acc: 0.4512 - val_loss: 36763.2894 - val_acc: 0.4661\n",
      "Epoch 21/50\n",
      "22667/22667 [==============================] - 2s - loss: 36626.1787 - acc: 0.4517 - val_loss: 36751.0719 - val_acc: 0.4584\n",
      "Epoch 22/50\n",
      "22667/22667 [==============================] - 2s - loss: 36599.2868 - acc: 0.4581 - val_loss: 36723.4299 - val_acc: 0.4616\n",
      "Epoch 23/50\n",
      "22667/22667 [==============================] - 2s - loss: 36583.1496 - acc: 0.4587 - val_loss: 36800.9877 - val_acc: 0.4539\n",
      "Epoch 24/50\n",
      "22667/22667 [==============================] - 2s - loss: 36575.3943 - acc: 0.4565 - val_loss: 36730.0452 - val_acc: 0.4606\n",
      "Epoch 25/50\n",
      "22667/22667 [==============================] - 2s - loss: 36559.0883 - acc: 0.4610 - val_loss: 36692.1524 - val_acc: 0.4654\n",
      "Epoch 26/50\n",
      "22667/22667 [==============================] - 2s - loss: 36540.8902 - acc: 0.4618 - val_loss: 36714.0931 - val_acc: 0.4629\n",
      "Epoch 27/50\n",
      "22667/22667 [==============================] - 2s - loss: 36526.8792 - acc: 0.4649 - val_loss: 36740.6114 - val_acc: 0.4566\n",
      "Epoch 28/50\n",
      "22667/22667 [==============================] - 2s - loss: 36518.7930 - acc: 0.4675 - val_loss: 36731.9006 - val_acc: 0.4736\n",
      "Epoch 29/50\n",
      "22667/22667 [==============================] - 2s - loss: 36506.6624 - acc: 0.4682 - val_loss: 36627.6581 - val_acc: 0.4826\n",
      "Epoch 30/50\n",
      "22667/22667 [==============================] - 2s - loss: 36491.1865 - acc: 0.4691 - val_loss: 36732.9317 - val_acc: 0.4684\n",
      "Epoch 31/50\n",
      "22667/22667 [==============================] - 2s - loss: 36486.5692 - acc: 0.4678 - val_loss: 36588.5787 - val_acc: 0.4856\n",
      "Epoch 32/50\n",
      "22667/22667 [==============================] - 2s - loss: 36476.8336 - acc: 0.4676 - val_loss: 36629.8371 - val_acc: 0.4804\n",
      "Epoch 33/50\n",
      "22667/22667 [==============================] - 2s - loss: 36468.2589 - acc: 0.4699 - val_loss: 36599.6990 - val_acc: 0.4814\n",
      "Epoch 34/50\n",
      "22667/22667 [==============================] - 2s - loss: 36460.7268 - acc: 0.4740 - val_loss: 36679.3869 - val_acc: 0.4589\n",
      "Epoch 35/50\n",
      "22667/22667 [==============================] - 2s - loss: 36448.1339 - acc: 0.4758 - val_loss: 36606.9283 - val_acc: 0.4974\n",
      "Epoch 36/50\n",
      "22667/22667 [==============================] - 2s - loss: 36442.4479 - acc: 0.4719 - val_loss: 36563.4811 - val_acc: 0.4984\n",
      "Epoch 37/50\n",
      "22667/22667 [==============================] - 2s - loss: 36433.6430 - acc: 0.4784 - val_loss: 36595.5321 - val_acc: 0.4926\n",
      "Epoch 38/50\n",
      "22667/22667 [==============================] - 2s - loss: 36430.2749 - acc: 0.4738 - val_loss: 36578.9650 - val_acc: 0.4876\n",
      "Epoch 39/50\n",
      "22667/22667 [==============================] - 2s - loss: 36423.4344 - acc: 0.4764 - val_loss: 36565.8336 - val_acc: 0.4841\n",
      "Epoch 40/50\n",
      "22667/22667 [==============================] - 2s - loss: 36411.5368 - acc: 0.4786 - val_loss: 36599.5296 - val_acc: 0.4899\n",
      "Epoch 41/50\n",
      "22667/22667 [==============================] - 2s - loss: 36410.2092 - acc: 0.4775 - val_loss: 36541.5603 - val_acc: 0.4931\n",
      "Epoch 42/50\n",
      "22667/22667 [==============================] - 2s - loss: 36403.0423 - acc: 0.4798 - val_loss: 36587.5814 - val_acc: 0.4894\n",
      "Epoch 43/50\n",
      "22667/22667 [==============================] - 2s - loss: 36401.0389 - acc: 0.4748 - val_loss: 36579.7204 - val_acc: 0.4884\n",
      "Epoch 44/50\n",
      "22667/22667 [==============================] - 2s - loss: 36391.0302 - acc: 0.4868 - val_loss: 36581.4422 - val_acc: 0.4744\n",
      "Epoch 45/50\n",
      "22667/22667 [==============================] - 2s - loss: 36391.8213 - acc: 0.4831 - val_loss: 36587.4716 - val_acc: 0.4809\n",
      "Epoch 46/50\n",
      "22667/22667 [==============================] - 2s - loss: 36386.1013 - acc: 0.4784 - val_loss: 36559.5106 - val_acc: 0.4774\n",
      "Epoch 47/50\n",
      "22667/22667 [==============================] - 2s - loss: 36372.3107 - acc: 0.4882 - val_loss: 36607.5639 - val_acc: 0.4856\n",
      "Epoch 48/50\n",
      "22667/22667 [==============================] - 2s - loss: 36370.2833 - acc: 0.4878 - val_loss: 36579.3085 - val_acc: 0.4831\n",
      "Epoch 49/50\n",
      "22667/22667 [==============================] - 2s - loss: 36372.4391 - acc: 0.4818 - val_loss: 36547.1418 - val_acc: 0.4924\n",
      "Epoch 50/50\n",
      "22667/22667 [==============================] - 2s - loss: 36362.7271 - acc: 0.4831 - val_loss: 36595.9449 - val_acc: 0.4769\n"
     ]
    }
   ],
   "source": [
    "autoencoder2, encoder2 = get_encoder(X_train, X_test, 1024, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22667, 1024)\n",
      "(4001, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = encoder2.predict(X_train)\n",
    "X_test = encoder2.predict(X_test)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22667 samples, validate on 4001 samples\n",
      "Epoch 1/50\n",
      "22667/22667 [==============================] - 1s - loss: 15102.8008 - acc: 0.0023 - val_loss: 14471.7531 - val_acc: 0.0037\n",
      "Epoch 2/50\n",
      "22667/22667 [==============================] - 1s - loss: 14662.7052 - acc: 0.0079 - val_loss: 14155.3762 - val_acc: 0.0167\n",
      "Epoch 3/50\n",
      "22667/22667 [==============================] - 1s - loss: 14318.1233 - acc: 0.1549 - val_loss: 13848.2065 - val_acc: 0.2659\n",
      "Epoch 4/50\n",
      "22667/22667 [==============================] - 1s - loss: 14035.5679 - acc: 0.2816 - val_loss: 13670.9940 - val_acc: 0.3114\n",
      "Epoch 5/50\n",
      "22667/22667 [==============================] - 1s - loss: 13839.5515 - acc: 0.3396 - val_loss: 13501.9122 - val_acc: 0.3667\n",
      "Epoch 6/50\n",
      "22667/22667 [==============================] - 1s - loss: 13695.6872 - acc: 0.3725 - val_loss: 13397.1453 - val_acc: 0.3949\n",
      "Epoch 7/50\n",
      "22667/22667 [==============================] - 1s - loss: 13585.0776 - acc: 0.3987 - val_loss: 13313.9699 - val_acc: 0.4401\n",
      "Epoch 8/50\n",
      "22667/22667 [==============================] - 1s - loss: 13500.4659 - acc: 0.4069 - val_loss: 13271.4230 - val_acc: 0.3894\n",
      "Epoch 9/50\n",
      "22667/22667 [==============================] - 1s - loss: 13429.3854 - acc: 0.4250 - val_loss: 13186.8064 - val_acc: 0.4294\n",
      "Epoch 10/50\n",
      "22667/22667 [==============================] - 1s - loss: 13371.7757 - acc: 0.4338 - val_loss: 13134.5740 - val_acc: 0.4441\n",
      "Epoch 11/50\n",
      "22667/22667 [==============================] - 1s - loss: 13324.2154 - acc: 0.4396 - val_loss: 13084.7089 - val_acc: 0.4634\n",
      "Epoch 12/50\n",
      "22667/22667 [==============================] - 1s - loss: 13283.6107 - acc: 0.4488 - val_loss: 13066.9244 - val_acc: 0.4996\n",
      "Epoch 13/50\n",
      "22667/22667 [==============================] - 1s - loss: 13248.9560 - acc: 0.4594 - val_loss: 13048.7752 - val_acc: 0.4681\n",
      "Epoch 14/50\n",
      "22667/22667 [==============================] - 1s - loss: 13213.9437 - acc: 0.4646 - val_loss: 13010.4436 - val_acc: 0.4221\n",
      "Epoch 15/50\n",
      "22667/22667 [==============================] - 1s - loss: 13189.7652 - acc: 0.4685 - val_loss: 12987.6364 - val_acc: 0.4741\n",
      "Epoch 16/50\n",
      "22667/22667 [==============================] - 1s - loss: 13166.0625 - acc: 0.4828 - val_loss: 12964.8651 - val_acc: 0.5049\n",
      "Epoch 17/50\n",
      "22667/22667 [==============================] - 1s - loss: 13145.0697 - acc: 0.4924 - val_loss: 12915.1589 - val_acc: 0.5341\n",
      "Epoch 18/50\n",
      "22667/22667 [==============================] - 1s - loss: 13126.4190 - acc: 0.4931 - val_loss: 12920.0055 - val_acc: 0.5254\n",
      "Epoch 19/50\n",
      "22667/22667 [==============================] - 1s - loss: 13107.5314 - acc: 0.4980 - val_loss: 12896.0994 - val_acc: 0.5224\n",
      "Epoch 20/50\n",
      "22667/22667 [==============================] - 1s - loss: 13093.5734 - acc: 0.5148 - val_loss: 12910.6895 - val_acc: 0.4894\n",
      "Epoch 21/50\n",
      "22667/22667 [==============================] - 1s - loss: 13078.1845 - acc: 0.5178 - val_loss: 12882.5694 - val_acc: 0.5119\n",
      "Epoch 22/50\n",
      "22667/22667 [==============================] - 1s - loss: 13069.9114 - acc: 0.5250 - val_loss: 12867.8821 - val_acc: 0.5221\n",
      "Epoch 23/50\n",
      "22667/22667 [==============================] - 1s - loss: 13055.6741 - acc: 0.5359 - val_loss: 12856.2297 - val_acc: 0.5266\n",
      "Epoch 24/50\n",
      "22667/22667 [==============================] - 1s - loss: 13046.5517 - acc: 0.5418 - val_loss: 12833.0178 - val_acc: 0.5749\n",
      "Epoch 25/50\n",
      "22667/22667 [==============================] - 1s - loss: 13038.2560 - acc: 0.5463 - val_loss: 12841.1810 - val_acc: 0.5659\n",
      "Epoch 26/50\n",
      "22667/22667 [==============================] - 1s - loss: 13028.3747 - acc: 0.5548 - val_loss: 12821.0676 - val_acc: 0.5676\n",
      "Epoch 27/50\n",
      "22667/22667 [==============================] - 1s - loss: 13022.2175 - acc: 0.5623 - val_loss: 12824.0048 - val_acc: 0.5566\n",
      "Epoch 28/50\n",
      "22667/22667 [==============================] - 1s - loss: 13013.0112 - acc: 0.5699 - val_loss: 12843.5573 - val_acc: 0.5474\n",
      "Epoch 29/50\n",
      "22667/22667 [==============================] - 1s - loss: 13009.9921 - acc: 0.5706 - val_loss: 12814.1798 - val_acc: 0.5841\n",
      "Epoch 30/50\n",
      "22667/22667 [==============================] - 1s - loss: 13003.4597 - acc: 0.5742 - val_loss: 12813.4194 - val_acc: 0.5956\n",
      "Epoch 31/50\n",
      "22667/22667 [==============================] - 1s - loss: 13000.2035 - acc: 0.5720 - val_loss: 12824.0753 - val_acc: 0.5874\n",
      "Epoch 32/50\n",
      "22667/22667 [==============================] - 1s - loss: 12994.6269 - acc: 0.5772 - val_loss: 12814.3962 - val_acc: 0.5814\n",
      "Epoch 33/50\n",
      "22667/22667 [==============================] - 1s - loss: 12988.7115 - acc: 0.5848 - val_loss: 12816.5386 - val_acc: 0.5806\n",
      "Epoch 34/50\n",
      "22667/22667 [==============================] - 1s - loss: 12987.0508 - acc: 0.5813 - val_loss: 12807.0005 - val_acc: 0.5916\n",
      "Epoch 35/50\n",
      "22667/22667 [==============================] - 1s - loss: 12982.0585 - acc: 0.5820 - val_loss: 12785.6939 - val_acc: 0.5961\n",
      "Epoch 36/50\n",
      "22667/22667 [==============================] - 1s - loss: 12978.3338 - acc: 0.5878 - val_loss: 12782.4536 - val_acc: 0.5866\n",
      "Epoch 37/50\n",
      "22667/22667 [==============================] - 1s - loss: 12975.7996 - acc: 0.5861 - val_loss: 12793.5071 - val_acc: 0.5944\n",
      "Epoch 38/50\n",
      "22667/22667 [==============================] - 1s - loss: 12974.2738 - acc: 0.5849 - val_loss: 12801.9628 - val_acc: 0.6086\n",
      "Epoch 39/50\n",
      "22667/22667 [==============================] - 1s - loss: 12970.0958 - acc: 0.5922 - val_loss: 12767.9917 - val_acc: 0.6023\n",
      "Epoch 40/50\n",
      "22667/22667 [==============================] - 1s - loss: 12967.1320 - acc: 0.5884 - val_loss: 12788.1872 - val_acc: 0.5934\n",
      "Epoch 41/50\n",
      "22667/22667 [==============================] - 1s - loss: 12966.9895 - acc: 0.5895 - val_loss: 12770.2220 - val_acc: 0.6046\n",
      "Epoch 42/50\n",
      "22667/22667 [==============================] - 1s - loss: 12961.5717 - acc: 0.5915 - val_loss: 12766.8960 - val_acc: 0.6061\n",
      "Epoch 43/50\n",
      "22667/22667 [==============================] - 1s - loss: 12960.9951 - acc: 0.5903 - val_loss: 12774.1154 - val_acc: 0.6008\n",
      "Epoch 44/50\n",
      "22667/22667 [==============================] - 1s - loss: 12959.2821 - acc: 0.5882 - val_loss: 12771.0662 - val_acc: 0.6051\n",
      "Epoch 45/50\n",
      "22667/22667 [==============================] - 1s - loss: 12956.6944 - acc: 0.5925 - val_loss: 12781.4170 - val_acc: 0.5839\n",
      "Epoch 46/50\n",
      "22667/22667 [==============================] - 1s - loss: 12958.5758 - acc: 0.5906 - val_loss: 12778.9262 - val_acc: 0.5934\n",
      "Epoch 47/50\n",
      "22667/22667 [==============================] - 1s - loss: 12954.3912 - acc: 0.5898 - val_loss: 12774.0733 - val_acc: 0.5989\n",
      "Epoch 48/50\n",
      "22667/22667 [==============================] - 1s - loss: 12951.8340 - acc: 0.5880 - val_loss: 12770.3073 - val_acc: 0.5906\n",
      "Epoch 49/50\n",
      "22667/22667 [==============================] - 1s - loss: 12948.6297 - acc: 0.5978 - val_loss: 12778.3022 - val_acc: 0.5971\n",
      "Epoch 50/50\n",
      "22667/22667 [==============================] - 1s - loss: 12949.4361 - acc: 0.5897 - val_loss: 12772.6706 - val_acc: 0.5836\n"
     ]
    }
   ],
   "source": [
    "autoencoder3, encoder3 = get_encoder(X_train, X_test, 512, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22667, 512)\n",
      "(4001, 512)\n"
     ]
    }
   ],
   "source": [
    "X_train = encoder3.predict(X_train)\n",
    "X_test = encoder3.predict(X_test)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
