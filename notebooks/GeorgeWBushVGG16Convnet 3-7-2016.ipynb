{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>George W Bush VGG16 Convnet 3-7-2016</h1>\n",
    "\n",
    "<strong>Abstract</strong> \n",
    "Trained VGG16 Convnet on 529 George W Bush images vs 1264 random images (excluding George W Bush) over 100 epochs resulting in 84% accuracy, test score of 1.22, 72.4% precision and 77.7% recall on our test set. Demonstrate it's possible to train a CNN to recognize a certain person's face among many other people's faces.\n",
    "\n",
    "<strong>Details</strong> Implemented VGG16 and trained it to identify George W Bush. He was chosen because of his high number of images, we would like to see how a CNN with a lot of images of a single person performs. George W Bush has 529 images and there are about 5,748 other people with a total of 12,643 images. But, we will discard 90% of the other images for performance leaving 1264 images.\n",
    "\n",
    "The final epoch of training on the CNN reaches 100% accuracy on test set and around 85% on validation set and took about 2 hours running on GeForce GT 650M 1GB. Images were resized to 100x100 dimensions. Models and weights have been persisted in the models folder.\n",
    "\n",
    "<strong>Recommendations</strong>\n",
    "<ul>\n",
    "<li>Consider training with minimal number of faces from the person of interest and compare against much more other random faces.</li>\n",
    "<li>Consider categorizing on many faces as a multi cateogorical problem rather than a binary problem.</li>\n",
    "<li>Reduce overfitting</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow \n",
    "from PIL import Image\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_lfw_path = data_path + 'lfw_cropped/'\n",
    "\n",
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "img_rows, img_cols = 100, 100\n",
    "train_size_percent = .85\n",
    "validation_split = .15\n",
    "random_discard_percent = .9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparing Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filenames_separated_from_target(target):\n",
    "    files = []\n",
    "    target_files = []\n",
    "    \n",
    "    for root, dirnames, filenames in os.walk(data_lfw_path):\n",
    "        for dirname in dirnames:\n",
    "                for filename in os.listdir(os.path.join(data_lfw_path, dirname)):\n",
    "                    if filename.endswith(\".jpg\"):\n",
    "                        f = os.path.join(root + dirname, filename)\n",
    "                        if dirname == target:\n",
    "                            target_files.append(f)\n",
    "                        else:\n",
    "                            files.append(f)\n",
    "                            \n",
    "    data_to_keep = int((1 - random_discard_percent) * len(files))\n",
    "    np.random.shuffle(files)\n",
    "    \n",
    "    return target_files, files[:data_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_and_test_sets(target_data, data):\n",
    "\n",
    "    all_data = [(t, 1) for t in target_data] + [(t, 0) for t in data]\n",
    "    np.random.shuffle(all_data)\n",
    "    \n",
    "    train_size = int(train_size_percent * len(all_data))\n",
    "    X_train = np.array([x[0] for x in all_data[:train_size]])\n",
    "    y_train = np.array([x[1] for x in all_data[:train_size]])\n",
    "    X_test = np.array([x[0] for x in all_data[train_size:]])  \n",
    "    y_test = np.array([x[1] for x in all_data[train_size:]])\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_read(f):\n",
    "    return resize(io.imread(f), (img_rows, img_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_files, files = get_filenames_separated_from_target('George_W_Bush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = [image_read(f) for f in files]\n",
    "target_images = [image_read(f) for f in target_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_train_and_test_sets(target_images, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train,2)\n",
    "Y_test = np_utils.to_categorical(y_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 1264)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_files), len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training and Testing the CNN</h2>\n",
    "\n",
    "Implementation of VGG-like convnet http://keras.io/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def VGG_16(optimizer, batch_size=16):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,img_rows,img_cols)))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VGG_16('sgd', batch_size)\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, mode='min')\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, \n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/GeorgeWBushVGG16Convnet.json', 'w').write(json_string)\n",
    "model.save_weights('models/GeorgeWBushVGG16Convnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model_from_json(open('models/GeorgeWBushVGG16Convnet.json').read())\n",
    "model.load_weights('models/GeorgeWBushVGG16Convnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 3s     \n",
      "('Test score:', 1.2175375433659466)\n",
      "('Test accuracy:', 0.84386617100371752)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, batch_size=16, show_accuracy=True, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[164,  24],\n",
       "       [ 18,  63]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72413793103448276"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77777777777777779"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
